{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "version 1.0.2\n",
    "#![ML Logo](https://raw.githubusercontent.com/chicochica10/utad-spark-ml/master/images/utad-spark-ml.1x_Banner_300.png)\n",
    "# **Un motor de recomendación con Apache Spark**\n",
    "## **Predicción de la clasificación (rating) de películas**\n",
    "#### Uno de los casos de uso más común del big data es predecir que es lo que el usuario quiere. Esto permite a Google mostrarte anuncios (ads) relevantes, a Amazon recomendarte productos y a Netflix recomendarte películas que podrían gustarte. En este lab demostraremos como usar Apache Spark para recomendar películas a para un usuario. Empezaremos con técnicas básicas y utilizaremos la librería de machine learning de Spark [Spark MLlib][mllib] en concreto el algoritmo de Mínimos cuadradados alternados (Alternating Least Squares) para hacer prediciones más sofisticadas.\n",
    "#### Utilizaremos un subset de 500.000 ratings de [movielens 10M stable benchmark rating dataset](http://grouplens.org/datasets/movielens/). El código sería el mismo para todo el dataset que tiene más de 21 millones de ratings.\n",
    "#### En este lab:\n",
    "#### *Parte 0*: Preliminares\n",
    "#### *Parte 1*: Recomendaciones básicas\n",
    "#### *Parte 2*: Filtros colaborativos\n",
    "#### *Parte 3*: Prediciones personalizadas para ti\n",
    "#### **Nota:** Cuidado con llamar a `collect()` en los datasets, si son pequeños no hay problema para ver como son los datos, pero si el dataset es grande no cabrán en la memoria donde se ejecuta el driver.\n",
    "[mllib]: https://spark.apache.org/mllib/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Código\n",
    "#### El lab se puede completar usando Python básico y transformaciones y acciones de pySpark. La única librería necesaria es math. Con la excepción de las funciones de ML que veremos todos los ejercicios se pueden completar con operaciones utilizadas previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from test_helper import Test\n",
    "\n",
    "baseDir = os.path.join('data')\n",
    "inputPath = os.path.join('utad-spark', 'lab4', 'small')\n",
    "\n",
    "ratingsFilename = os.path.join(baseDir, inputPath, 'ratings.dat.gz')\n",
    "moviesFilename = os.path.join(baseDir, inputPath, 'movies.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte 0: Preliminares**\n",
    "#### Leeremos el fichero línea a línea y crearemos un RDD con la líneas parseadas.\n",
    "#### Cada línea en el dataset de ratings (`ratings.dat.gz`) está formateada como:\n",
    "####   `UserID::MovieID::Rating::Timestamp`\n",
    "#### Cada línea en el dataset de películas (`movies.dat`) está formateada como:\n",
    "####   `MovieID::Title::Genres`\n",
    "#### El campo `Genres` tiene el siguiente formato:\n",
    "####   `Genres1|Genres2|Genres3|...`\n",
    "#### El formato de estos ficheros es uniforme y simple por lo que podemos utilizar [`split()`](https://docs.python.org/2/library/stdtypes.html#str.split) de Python para parsear las líneas.\n",
    "#### El parseo de los dos ficheros devolverá dos RDDs.\n",
    "* #### Para cada línea en el dataset de ratings crearemos una tupla de (UserID, MovieID, Rating). Descartamos el timestamp porque no lo necesitaremos para este ejercicio.\n",
    "* #### Para cada línea en el dataset de pelis crearemos una tupla de (MovieID, Title). Descartamos Genres porque no lo necesitaremos para este ejercicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay 487650 ratings y 3883 pelis en los datasets\n",
      "Ratings: [(1, 1193, 5.0), (1, 914, 3.0), (1, 2355, 5.0)]\n",
      "Pelis: [(1, u'Toy Story (1995)'), (2, u'Jumanji (1995)'), (3, u'Grumpier Old Men (1995)')]\n"
     ]
    }
   ],
   "source": [
    "numPartitions = 2\n",
    "rawRatings = sc.textFile(ratingsFilename).repartition(numPartitions)\n",
    "rawMovies = sc.textFile(moviesFilename)\n",
    "\n",
    "def get_ratings_tuple(entry):\n",
    "    \"\"\" Parsea una línea en el dataset de ratings\n",
    "    Args:\n",
    "        entry (str): una linea en el dataset de ratings de la forma UserID::MovieID::Rating::Timestamp\n",
    "    Returns:\n",
    "        tuple: (UserID, MovieID, Rating)\n",
    "    \"\"\"\n",
    "    items = entry.split('::')\n",
    "    return int(items[0]), int(items[1]), float(items[2])\n",
    "\n",
    "\n",
    "def get_movie_tuple(entry):\n",
    "    \"\"\" Parsea una línea del dataset de pelis\n",
    "    Args:\n",
    "        entry (str): una línea en el dataset de pelis de la forma of MovieID::Title::Genres\n",
    "    Returns:\n",
    "        tuple: (MovieID, Title)\n",
    "    \"\"\"\n",
    "    items = entry.split('::')\n",
    "    return int(items[0]), items[1]\n",
    "\n",
    "\n",
    "ratingsRDD = rawRatings.map(get_ratings_tuple).cache() #RDD [(UserID, MovieID, Rating)]\n",
    "moviesRDD = rawMovies.map(get_movie_tuple).cache() #RDD [(MovieID, Title)]\n",
    "\n",
    "ratingsCount = ratingsRDD.count()\n",
    "moviesCount = moviesRDD.count()\n",
    "\n",
    "print 'Hay %s ratings y %s pelis en los datasets' % (ratingsCount, moviesCount)\n",
    "print 'Ratings: %s' % ratingsRDD.take(3)\n",
    "print 'Pelis: %s' % moviesRDD.take(3)\n",
    "\n",
    "assert ratingsCount == 487650\n",
    "assert moviesCount == 3883\n",
    "assert moviesRDD.filter(lambda (id, title): title == 'Toy Story (1995)').count() == 1\n",
    "assert (ratingsRDD.takeOrdered(1, key=lambda (user, movie, rating): movie)\n",
    "        == [(1, 1, 5.0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En este lab examinaremos subsets de las tuplas que hemos creado (por ejemplo, las pelis mejor calificadas por los usuarios). Ya que sólo es un subset de una dataset grande el resultado puede depender del orden en que se realicen las operaciones como los joins o como se hayan particionado los datos por los workers. Para garantizar que siempre se mostrarán los mismos resultados para un subset independientemente de como se hayan manipulado o almacenado los datos podemos ordenar el subset antes de examinarlo. La elección más obvia puede ser utilizar [`sortByKey()`][sortbykey] pero esta elección puede ser problemática ya que puede dar diferentes resultados si la key no es única.\n",
    "#### Nota: es importante utilizar el [ tipo `unicode`](https://docs.python.org/2/howto/unicode.html#the-unicode-type) en vez del tipo `string` ya que los títulos están en codificados en unicode.\n",
    "#### Considera el siguiente ejemplo, mientras que que los conjuntos son iguales, las listas impresas están normalmente en orden de valor diferente *aunque pueden casar de vez en cuando*\n",
    "#### Puedes probar a ejecutar varias veces. Si falla el último assert no te preocupes que puede pasar.\n",
    "[sortbykey]: https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.sortByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, u'alpha'), (1, u'epsilon'), (1, u'delta'), (2, u'alpha'), (2, u'beta'), (3, u'alpha')]\n",
      "[(1, u'delta'), (1, u'epsilon'), (1, u'alpha'), (2, u'alpha'), (2, u'beta'), (3, u'alpha')]\n"
     ]
    }
   ],
   "source": [
    "tmp1 = [(1, u'alpha'), (2, u'alpha'), (2, u'beta'), (3, u'alpha'), (1, u'epsilon'), (1, u'delta')]\n",
    "tmp2 = [(1, u'delta'), (2, u'alpha'), (2, u'beta'), (3, u'alpha'), (1, u'epsilon'), (1, u'alpha')]\n",
    "\n",
    "oneRDD = sc.parallelize(tmp1)\n",
    "twoRDD = sc.parallelize(tmp2)\n",
    "oneSorted = oneRDD.sortByKey(True).collect()\n",
    "twoSorted = twoRDD.sortByKey(True).collect()\n",
    "print oneSorted\n",
    "print twoSorted\n",
    "assert set(oneSorted) == set(twoSorted)     # ambas listas tienen los mismos elementos\n",
    "assert twoSorted[0][0] < twoSorted.pop()[0] # comprobar que están ordenadas por key\n",
    "assert oneSorted[0:2] != twoSorted[0:2]     # el subset de los dos primeros elementos no casa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aunque  las dos listas contengan tuplas idénticas la diferencia en la ordenacion *a veces* devuelve una ordenación diferente para el RDD ordenado (prueba a correr la celda repetidamente y ver si cambia el resultado o falla el último assert). Si sólo examinamos los dos primeros elementos del RDD (por ejemplo usando `take(2)`), podríamos observar respuestas diferentes **esto es una mala salida ya que queremos que entradas identicas produzcan resultados idénticos**. Una técnica de ordenación mejor es ordenar un RDD *por clave y valor* lo que podemos conseguir combinando ambos en una única string y ordenándola. Ya que la key es un entero y el valor una string unicode, usaremos una función que combine ambas en una única string unicode (por ejemplo `unicode('%.3f' % key) + ' ' + value`) antes de ordenar el RDD usando [sortBy()][sortby].\n",
    "[sortby]: https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.sortBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, u'alpha'), (1, u'delta'), (1, u'epsilon'), (2, u'alpha'), (2, u'beta'), (3, u'alpha')]\n",
      "[(1, u'alpha'), (1, u'delta'), (1, u'epsilon'), (2, u'alpha'), (2, u'beta'), (3, u'alpha')]\n"
     ]
    }
   ],
   "source": [
    "def sortFunction(tuple):\n",
    "    \"\"\" construye una Strig para ordenación (no realiza una ordenación real) \n",
    "    Args:\n",
    "        tuple: (rating, MovieName)\n",
    "    Returns:\n",
    "        sortString: el valor a ordenar: 'rating MovieName'\n",
    "    \"\"\"\n",
    "    key = unicode('%.3f' % tuple[0])\n",
    "    value = tuple[1]\n",
    "    return (key + ' ' + value)\n",
    "\n",
    "\n",
    "print oneRDD.sortBy(sortFunction, True).collect()\n",
    "print twoRDD.sortBy(sortFunction, True).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Si solo queremos ver los primeros elementos del RDD de manera ordenada podemos usar el método [takeOrdered] con la función `sortFunction` que hemos definido.\n",
    "[takeordered]: https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.takeOrdered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one es [(1, u'alpha'), (1, u'delta'), (1, u'epsilon'), (2, u'alpha'), (2, u'beta'), (3, u'alpha')]\n",
      "two es [(1, u'alpha'), (1, u'delta'), (1, u'epsilon'), (2, u'alpha'), (2, u'beta'), (3, u'alpha')]\n"
     ]
    }
   ],
   "source": [
    "oneSorted1 = oneRDD.takeOrdered(oneRDD.count(),key=sortFunction)\n",
    "twoSorted1 = twoRDD.takeOrdered(twoRDD.count(),key=sortFunction)\n",
    "print 'one es %s' % oneSorted1\n",
    "print 'two es %s' % twoSorted1\n",
    "assert oneSorted1 == twoSorted1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte 1: Recomendaciones básicas**\n",
    "#### Una forma de recomendar pelis es recomendar siempre las pelis con el rating medio más alto. En esta parte usaremos Spark para encontrar el nombre, número de ratings y la media de rating de las 20 pelis con el rating medio más alto y que tenga más de 500 críticas (reviews) . Vamos a eliminar las pelis con ratings altos pero con menos de (o igual a) 500 reviews porque pueden no tener suficiente atractivo para todo el mundo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1a) Número de ratings y media de ratings para una peli**\n",
    "#### Usando sólo Python, implementa una función auxiliar `getCountsAndAverages()` que tome una tupla de (MovieID, (Rating1, Rating2, Rating3, ...)) y devuelva una tupla de (MovieID, (number of ratings, averageRating)). Por ejemplo dada la tupla `(100, (10.0, 20.0, 30.0))`, debería devolver `(100, (3, 20.0))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Sustituye <RELLENA> con código apropiado\n",
    "\n",
    "# Primero implementa la función auxiliar `getCountsAndAverages` usando sólo Python\n",
    "def getCountsAndAverages(IDandRatingsTuple):\n",
    "    \"\"\" Calcula el rating medio\n",
    "    Args:\n",
    "        IDandRatingsTuple: una única tupla de (MovieID, (Rating1, Rating2, Rating3, ...))\n",
    "    Returns:\n",
    "        tuple: una tupla de (MovieID, (number of ratings, averageRating))\n",
    "    \"\"\"\n",
    "    movieId = IDandRatingsTuple[0]\n",
    "    ratings = IDandRatingsTuple[1]\n",
    "    ratingsSize = 0\n",
    "    ratingsSum = 0\n",
    "    for rating in ratings:\n",
    "        ratingsSize = ratingsSize + 1\n",
    "        ratingsSum = ratingsSum + rating\n",
    "     \n",
    "    return (int(movieId), (int(ratingsSize), float (ratingsSum)/ratingsSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Número de Ratings y media de Ratings para una peli (1a)\n",
    "\n",
    "Test.assertEquals(getCountsAndAverages((1, (1, 2, 3, 4))), (1, (4, 2.5)),\n",
    "                            'getCountsAndAverages() incorrecto con la lista de enteros')\n",
    "Test.assertEquals(getCountsAndAverages((100, (10.0, 20.0, 30.0))), (100, (3, 20.0)),\n",
    "                            'getCountsAndAverages() incorrecto con la lista de float')\n",
    "Test.assertEquals(getCountsAndAverages((110, xrange(20))), (110, (20, 9.5)),\n",
    "                            'getCountsAndAverages() incorrecto con xrange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1b) Pelis con la media de ratings más alta**\n",
    "#### Ahora que podemos calcular la media de ratings, usaremos `getCountsAndAverages()` con Spark para determinar las pelis con la media de ratings más alta.\n",
    "#### Los pasos a realizar son:\n",
    "* #### Teniendo en cuenta que `ratingsRDD` contiene tuplas de la form (UserID, MovieID, Rating). Desde `ratingsRDD` crear un RDD con tuplas de la forma (MovieID, Python iterable de Ratings para ese MovieID). Esta transformación devolverá un RDD de la forma: `[(1, <pyspark.resultiterable.ResultIterable object at 0x7f16d50e7c90>), (2, <pyspark.resultiterable.ResultIterable object at 0x7f16d50e79d0>), (3, <pyspark.resultiterable.ResultIterable object at 0x7f16d50e7610>)]`. Sólo necesitaremos hacer dos transformaciones Spark para hacer este paso.\n",
    "* #### Usando `movieIDsWithRatingsRDD` y `getCountsAndAverages()` calcula el número de ratings y la media de ratings para cada peli para devolver tuplas de la forma (MovieID, (number of ratings, average rating)). Ejemplo: `[(1, (993, 4.145015105740181)), (2, (332, 3.174698795180723)), (3, (299, 3.0468227424749164))]`. Puedes hacer esto con una única transformación de Spark\n",
    "* #### Queremos ver los nombres de las pelis en vez de sus IDs. A `moviesRDD`, aplícale transformaciones que usen `movieIDsWithAvgRatingsRDD` para obtener los nombres de las pelis para `movieIDsWithAvgRatingsRDD`, devolviendo tuplas de la forma (media de rating, nombre de peli, número de ratings). Este conjunto de transformaciones devolverá un RDD de la forma `[(1.0, u'Autopsy (Macchie Solari) (1975)', 1), (1.0, u'Better Living (1998)', 1), (1.0, u'Big Squeeze, The (1996)', 3)]`. Necesitarás dos transformaciones de Spark para completar este paso: Primero usa `moviesRDD` con `movieIDsWithAvgRatingsRDD` para crear un nuevo RDD con los nombres de pelis que casen con los IDs de pelis y luego convierte el contenido de ese RDD en tuplas de (media de ratings, nombre de peli, número de rating). Estas transformaciones devolverán un RDD con el siguiente aspecto: `[(3.6818181818181817, u'Happiest Millionaire, The (1967)', 22), (3.0468227424749164, u'Grumpier Old Men (1995)', 299), (2.882978723404255, u'Hocus Pocus (1993)', 94)]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movieIDsWithRatingsRDD: [(2, <pyspark.resultiterable.ResultIterable object at 0xb0ee79ec>), (4, <pyspark.resultiterable.ResultIterable object at 0xb0ee7b8c>), (6, <pyspark.resultiterable.ResultIterable object at 0xb0ee7a2c>)]\n",
      "\n",
      "movieIDsWithAvgRatingsRDD: [(2, (332, 3.174698795180723)), (4, (71, 2.676056338028169)), (6, (442, 3.7918552036199094))]\n",
      "\n",
      "movieNameWithAvgRatingsRDD: [(3.6818181818181817, u'Happiest Millionaire, The (1967)', 22), (3.0468227424749164, u'Grumpier Old Men (1995)', 299), (2.882978723404255, u'Hocus Pocus (1993)', 94)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Sustituye <RELLENA> con código apropiado\n",
    "\n",
    "# Para ratingsRDD con tuplas de (UserID, MovieID, Rating) crea un RDD con tuplas de\n",
    "#  (MovieID, iterable de ratings para ese MovieID)\n",
    "#RDD [(movieID, [rat1, rat2,...])]\n",
    "movieIDsWithRatingsRDD = ratingsRDD.map (lambda (userId, movieId, rating): (movieId, rating)).groupByKey ()\n",
    "\n",
    "print 'movieIDsWithRatingsRDD: %s\\n' % movieIDsWithRatingsRDD.take(3)\n",
    "\n",
    "# Usando `movieIDsWithRatingsRDD`, calcula el número de ratings y la media de ratings para cada peli\n",
    "# para devolver tuplas de la forma (MovieID, (número de ratings, media de ratings))\n",
    "#RDD [(MovieID, (número de ratings, media de ratings))]\n",
    "movieIDsWithAvgRatingsRDD = movieIDsWithRatingsRDD.map (lambda IDandRatingsTuple: getCountsAndAverages(IDandRatingsTuple))\n",
    "\n",
    "print 'movieIDsWithAvgRatingsRDD: %s\\n' % movieIDsWithAvgRatingsRDD.take(3)\n",
    "\n",
    "# A `movieIDsWithAvgRatingsRDD`, aplícale transformaciones RDD que usen `moviesRDD` para obtener el nombre\n",
    "# de la peli para `movieIDsWithAvgRatingsRDD`, devolviendo tuplas de la forma\n",
    "# (media de rating, nombre de la peli, número de ratings)\n",
    "\n",
    "##moviesRDD : RDD [(MovieID, Title)]\n",
    "movieNameWithAvgRatingsRDD = moviesRDD.join (movieIDsWithAvgRatingsRDD).map (lambda rec: (rec[1][1][1], rec[1][0], rec[1][1][0]))\n",
    "#movieNameWithAvgRatingsRDD : RDD[(media de rating, nombre de la peli, número de ratings)]\n",
    "\n",
    "print 'movieNameWithAvgRatingsRDD: %s\\n' % movieNameWithAvgRatingsRDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Pelis con la media de ratings más alta (1b)\n",
    "\n",
    "Test.assertEquals(movieIDsWithRatingsRDD.count(), 3615,\n",
    "                'movieIDsWithRatingsRDD.count() incorrecto (esperado 3615)')\n",
    "movieIDsWithRatingsTakeOrdered = movieIDsWithRatingsRDD.takeOrdered(3)\n",
    "Test.assertTrue(movieIDsWithRatingsTakeOrdered[0][0] == 1 and\n",
    "                len(list(movieIDsWithRatingsTakeOrdered[0][1])) == 993,\n",
    "                'count of ratings for movieIDsWithRatingsTakeOrdered[0] incorrecto (esperado 993)')\n",
    "Test.assertTrue(movieIDsWithRatingsTakeOrdered[1][0] == 2 and\n",
    "                len(list(movieIDsWithRatingsTakeOrdered[1][1])) == 332,\n",
    "                'count of ratings for movieIDsWithRatingsTakeOrdered[1] incorrecto (esperado 332)')\n",
    "Test.assertTrue(movieIDsWithRatingsTakeOrdered[2][0] == 3 and\n",
    "                len(list(movieIDsWithRatingsTakeOrdered[2][1])) == 299,\n",
    "                'count of ratings for movieIDsWithRatingsTakeOrdered[2] incorrecto (esperado 299)')\n",
    "\n",
    "Test.assertEquals(movieIDsWithAvgRatingsRDD.count(), 3615,\n",
    "                'movieIDsWithAvgRatingsRDD.count() incorrecto (esperado 3615)')\n",
    "Test.assertEquals(movieIDsWithAvgRatingsRDD.takeOrdered(3),\n",
    "                [(1, (993, 4.145015105740181)), (2, (332, 3.174698795180723)),\n",
    "                 (3, (299, 3.0468227424749164))],\n",
    "                'movieIDsWithAvgRatingsRDD.takeOrdered(3) incorrecto')\n",
    "\n",
    "Test.assertEquals(movieNameWithAvgRatingsRDD.count(), 3615,\n",
    "                'movieNameWithAvgRatingsRDD.count() incorrecto (esperado 3615)')\n",
    "Test.assertEquals(movieNameWithAvgRatingsRDD.takeOrdered(3),\n",
    "                [(1.0, u'Autopsy (Macchie Solari) (1975)', 1), (1.0, u'Better Living (1998)', 1),\n",
    "                 (1.0, u'Big Squeeze, The (1996)', 3)],\n",
    "                 'movieNameWithAvgRatingsRDD.takeOrdered(3) incorrecto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1c) Pelis con las medias más altas de rating y más de 500 reviews**\n",
    "#### Ahora que tenemos un RDD de pelis con los medias de ratings más altas podemos usar Spark para determinar las 20 pelis de ese RDD con más de 500 reviews.\n",
    "#### Aplica una única transformación a `movieNameWithAvgRatingsRDD` para limitar el número de resultados de pelis con ratings de mas de 500 personas, después usa la función `sortFunction()` para ordenar por media de rating obteniendo las que tengan mayor rating primero. Tendrás un RDD de la siguiente forma: `[(4.5349264705882355, u'Shawshank Redemption, The (1994)', 1088), (4.515798462852263, u\"Schindler's List (1993)\", 1171), (4.512893982808023, u'Godfather, The (1972)', 1047)]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pelis con los ratings más altos: [(4.5349264705882355, u'Shawshank Redemption, The (1994)', 1088), (4.515798462852263, u\"Schindler's List (1993)\", 1171), (4.512893982808023, u'Godfather, The (1972)', 1047), (4.510460251046025, u'Raiders of the Lost Ark (1981)', 1195), (4.505415162454874, u'Usual Suspects, The (1995)', 831), (4.457256461232604, u'Rear Window (1954)', 503), (4.45468509984639, u'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)', 651), (4.43953006219765, u'Star Wars: Episode IV - A New Hope (1977)', 1447), (4.4, u'Sixth Sense, The (1999)', 1110), (4.394285714285714, u'North by Northwest (1959)', 700), (4.379506641366224, u'Citizen Kane (1941)', 527), (4.375, u'Casablanca (1942)', 776), (4.363975155279503, u'Godfather: Part II, The (1974)', 805), (4.358816276202219, u\"One Flew Over the Cuckoo's Nest (1975)\", 811), (4.358173076923077, u'Silence of the Lambs, The (1991)', 1248), (4.335826477187734, u'Saving Private Ryan (1998)', 1337), (4.326241134751773, u'Chinatown (1974)', 564), (4.325383304940375, u'Life Is Beautiful (La Vita \\ufffd bella) (1997)', 587), (4.324110671936759, u'Monty Python and the Holy Grail (1974)', 759), (4.3096, u'Matrix, The (1999)', 1250)]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Sustituye <RELLENA> con código apropiado\n",
    "\n",
    "# Aplica una transformación RDD a movieNameWithAvgRatingsRDD` para limitar los resultados de las pelis con\n",
    "# ratings de más de 500 personas. Usa `sortFunction()` para ordenar por\n",
    "# media de rating y obtener la pelis ordenada por su rating  (los ratings mayores primero)\n",
    "#movieNameWithAvgRatingsRDD: RDD[(media de rating, nombre de la peli, número de ratings)]\n",
    "movieLimitedAndSortedByRatingRDD = (movieNameWithAvgRatingsRDD\n",
    "                                    .filter (lambda rec: rec[2] > 500)\n",
    "                                    .sortBy(sortFunction, False))\n",
    "print 'Pelis con los ratings más altos: %s' % movieLimitedAndSortedByRatingRDD.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Pelis con la media de ratings más alta y mas de 500 reviews (1c)\n",
    "\n",
    "Test.assertEquals(movieLimitedAndSortedByRatingRDD.count(), 194,\n",
    "                'movieLimitedAndSortedByRatingRDD.count() incorrecto')\n",
    "Test.assertEquals(movieLimitedAndSortedByRatingRDD.take(20),\n",
    "              [(4.5349264705882355, u'Shawshank Redemption, The (1994)', 1088),\n",
    "               (4.515798462852263, u\"Schindler's List (1993)\", 1171),\n",
    "               (4.512893982808023, u'Godfather, The (1972)', 1047),\n",
    "               (4.510460251046025, u'Raiders of the Lost Ark (1981)', 1195),\n",
    "               (4.505415162454874, u'Usual Suspects, The (1995)', 831),\n",
    "               (4.457256461232604, u'Rear Window (1954)', 503),\n",
    "               (4.45468509984639, u'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)', 651),\n",
    "               (4.43953006219765, u'Star Wars: Episode IV - A New Hope (1977)', 1447),\n",
    "               (4.4, u'Sixth Sense, The (1999)', 1110), (4.394285714285714, u'North by Northwest (1959)', 700),\n",
    "               (4.379506641366224, u'Citizen Kane (1941)', 527), (4.375, u'Casablanca (1942)', 776),\n",
    "               (4.363975155279503, u'Godfather: Part II, The (1974)', 805),\n",
    "               (4.358816276202219, u\"One Flew Over the Cuckoo's Nest (1975)\", 811),\n",
    "               (4.358173076923077, u'Silence of the Lambs, The (1991)', 1248),\n",
    "               (4.335826477187734, u'Saving Private Ryan (1998)', 1337),\n",
    "               (4.326241134751773, u'Chinatown (1974)', 564),\n",
    "               (4.325383304940375, u'Life Is Beautiful (La Vita \\ufffd bella) (1997)', 587),\n",
    "               (4.324110671936759, u'Monty Python and the Holy Grail (1974)', 759),\n",
    "               (4.3096, u'Matrix, The (1999)', 1250)], 'incorrecto sortedByRatingRDD.take(20)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando un threshold en el número de reviews podemos mejorar las recomendaciones pero hay otras formas de mejorar la calidad como por ejemplo ponderar los ratings por el número de ratings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Parte 2: Filtros Colaborativos**\n",
    "#### Spark posee una librería de Machine Learning llamada  [MLlib][mllib].  En esta parte aprenderemos como utilizar MLib para hacer recomendaciones de pelis personalizadas utilizando los datos de las pelis.\n",
    "#### Vamos a utilizar una técnica llamada [Filtro colaborativo (collaborative filtering)][collab]. El filtro colaborativo es un método para hacer prediciones automáticas (filtro) sobre los intereses de un usuario en base a las preferencias de otros usuarios (colaborativo). La idea de un filtro colaborativo es que si a una persona A que tiene la misma opinión que otra persona B respecto a algo, es más problable que la opinión de B en otro a otro asunto x sea igual que la de A que la de otra pesona elegida al azar. Puedes leer más sobre filtros colaborativos  [aquí][collab2].\n",
    "#### La imagen de abajo ([Wikipedia][collab]) muestra un ejemplo de predicción de los rating de un usuario utilizando un filtro colaborativo. En primer lugar, la gente califica diferentes items (como vídeos, imagenes, juegos). Despúes el sistema hace prediciones sobre el rating de un usuario para un item que el usuario aún no ha calificado. Estas prediciones se construyen sobre los ratings existentes de otros usuarios que tienen ratings similares con el usuario activo. Por ejemplo en la imagen el sistema ha hecho la predición de que al usuario activo no le gustará el vídeo.\n",
    "![collaborative filtering](https://courses.edx.org/c4x/BerkeleyX/CS100.1x/asset/Collaborative_filtering.gif)\n",
    "[mllib]: https://spark.apache.org/mllib/\n",
    "[collab]: https://en.wikipedia.org/?title=Collaborative_filtering\n",
    "[collab2]: http://recommender-systems.org/collaborative-filtering/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para recomendar peliculas empezaremos con una matriz cuyas entradas son ratings de usuarios (en rojo en el diagrama de abajo). Cada columna representa a un usuario (en verde) y cada fila representa una película en particular (en azul).\n",
    "#### Ya que no todos los usuarios han calificado todas las pelis, no conocemos todas las entradas de la matriz que es precisamente por lo que necesitamos un filtro colaborativo. Para cada usuario tenemos ratings sólo para un subset de las pelis. Con el filtro colaborativo la idea es aproximar la matriz de ratings factorizada como el producto de dos matrices: una que describe las propiedades de cada usuario (en verde) y otra que describe las propiedades de cada peli (en azul)\n",
    "\n",
    "![factorization](https://raw.githubusercontent.com/chicochica10/utad-spark-ml/master/images/matrix_factorization.png)\n",
    "#### Queremos selecionar estas dos matrices de tal forma que el error para los pares usuarios/pelis sobre los que conocemos los ratings correctos este minimizado. El algoritmo de  [Mínimos cuadrados alternados (Alternating Least Squares)][als] hace esta tarea rellenando primero de manera aleatoria la matriz de usuarios con valores y después optimizando el valor de pelis para las que el error se minimiza. Depués fija la matriz de pelis para contrastar y optimiza el valor de la matriz de usuarios. Esta alternancia entre las matrices a optimizar es la razón por la que se usa el nombre de alternados.\n",
    "#### Esta optimización es lo que se muestra a la derecha de la imagen de abajo. Dado un conjunto fijo de factores de usuario (por ejemplo los valores en la matriz de usuario) utilizamos los ratings conocidos para encontrar el mejor valor para los factores de película utilizando la optimización escrita abajo. Después \"alternamos\" y cogemos los mejores factores de usuario dejando fijos los factores de película\n",
    "#### Para ver un ejemplo simple de como son las matrices de usuario y pelis revisa las transparencias.\n",
    "\n",
    "[als]: https://en.wikiversity.org/wiki/Least-Squares_Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2a) Creando un Conjunto de entrenamiento (Traininig Set)**\n",
    "#### Antes de utilizar el algortimo de machine learning, necesitamos romper el dataset `ratingsRDD` en tres trozos:\n",
    "* #### Un training set (RDD), que utilizaremos para entrenar modelos\n",
    "* #### Un set de validación (RDD), que utilizaremos para elegir el mejor modelo\n",
    "* #### Un set de test (RDD), que utilizaremos para nuestros experimentos\n",
    "#### Para partir el dataset en múltiples grupos podemos utilizar pySpark [randomSplit()](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.randomSplit) . `randomSplit()` tomoa un conjunto de splits y devuelve multiples RDDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 292716, validación: 96902, test: 98032\n",
      "\n",
      "[(1, 914, 3.0), (1, 2355, 5.0), (1, 595, 5.0)]\n",
      "[(1, 1287, 5.0), (1, 594, 4.0), (1, 1270, 5.0)]\n",
      "[(1, 1193, 5.0), (1, 2398, 4.0), (1, 1035, 5.0)]\n"
     ]
    }
   ],
   "source": [
    "##ratings ->RDD [(UserID, MovieID, Rating)]\n",
    "trainingRDD, validationRDD, testRDD = ratingsRDD.randomSplit([6, 2, 2], seed=0L)\n",
    "\n",
    "print 'Training: %s, validación: %s, test: %s\\n' % (trainingRDD.count(),\n",
    "                                                    validationRDD.count(),\n",
    "                                                    testRDD.count())\n",
    "print trainingRDD.take(3)\n",
    "print validationRDD.take(3)\n",
    "print testRDD.take(3)\n",
    "\n",
    "assert trainingRDD.count() == 292716\n",
    "assert validationRDD.count() == 96902\n",
    "assert testRDD.count() == 98032\n",
    "\n",
    "assert trainingRDD.filter(lambda t: t == (1, 914, 3.0)).count() == 1\n",
    "assert trainingRDD.filter(lambda t: t == (1, 2355, 5.0)).count() == 1\n",
    "assert trainingRDD.filter(lambda t: t == (1, 595, 5.0)).count() == 1\n",
    "\n",
    "assert validationRDD.filter(lambda t: t == (1, 1287, 5.0)).count() == 1\n",
    "assert validationRDD.filter(lambda t: t == (1, 594, 4.0)).count() == 1\n",
    "assert validationRDD.filter(lambda t: t == (1, 1270, 5.0)).count() == 1\n",
    "\n",
    "assert testRDD.filter(lambda t: t == (1, 1193, 5.0)).count() == 1\n",
    "assert testRDD.filter(lambda t: t == (1, 2398, 4.0)).count() == 1\n",
    "assert testRDD.filter(lambda t: t == (1, 1035, 5.0)).count() == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Después de partir el dataset, el de entrenamiento tendrá unas 293.000 entradas y los de validación y test tendrán cada uno unas 97.000 (el número de entradas en cada dataset puede variar ligeramente debido a la naturaleza aleatoria de la transformación `randomSplit()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2b) Error Cuadrático medio - Root Mean Square Error (RMSE)**\n",
    "#### En esta parte generaremos unos pocos modelos diferentes y necesitaremos una forma de decidir que modelo es el mejor. Utilizaremos  [Root Mean Square Error](https://en.wikipedia.org/wiki/Root-mean-square_deviation) (RMSE)  o Desviación cuadrática media - Root Mean Square Deviation (RMSD) para calcular el error de cada modelo. RMSE se usa frecuentemente para medir diferencias entre valores (valores de una muestra y de toda la población) predicho por un modelo y los valores realmente observados. Las diferencias individuales se llaman residuos cuando los cálculos se realizan sobre la muestra de datos que es utilizada para la estimación y se llaman errores de predicción cuando se calculan para un dataset que no es de muestra. RMSE sirve para agregar las magnitudes de los errores en las predicciones en un proceso iterativo en una única medida de poder predictivo. RMSE es una buena medida de precisión para comparar errores de predicción de diferentes modelos para una variable particular pero no entre variables ya que depende de la escala.\n",
    "#### El RMSE es la raíz cuadrada de la media de de (rating real - rating predicho) para todos los usuario y pelis para los que tenemos un rating real. A partir de la versión de Spark 1.4 existe el módulos [RegressionMetrics](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.evaluation.RegressionMetrics) que se puede utilizar para calcular RMSE. Pero para ver como hacerlo lo construiremos nosotros mismos\n",
    "#### Vamos a escribir una función para calcular la suma de los errores cuadráticos sobre `predictedRDD` y `actualRDD` que tienen tuplas de la forma (UserID, MovieID, Rating)\n",
    "#### Dados dos RDDs de ratings *x* e *y* con n tamaño *n* definimos RSME como: $ RMSE = \\sqrt{\\frac{\\sum_{i = 1}^{n} (x_i - y_i)^2}{n}}$\n",
    "#### Para calcular el RMSE, los pasos a realizar son:\n",
    "* #### Transformar `predictedRDD` en tuplas ((UserID, MovieID), Rating). Por ejemplo tuplas como `[((1, 1), 5), ((1, 2), 3), ((1, 3), 4), ((2, 1), 3), ((2, 2), 2), ((2, 3), 4)]`. Puedes realizar este paso con una única transformación de Spark.\n",
    "* #### Transformar `actualRDD` en tuplas ((UserID, MovieID), Rating). Por ejemplo tuplas como `[((1, 2), 3), ((1, 3), 5), ((2, 1), 5), ((2, 2), 1)]`. Puedes realizar este paso con una única transformación Spark.\n",
    "* #### Utilizando únicamente transformaciones RDD (solo necesitaremos dos) calcular el error cuadrático para cada entrada que haga *matching* (esto es el mismo (UserID, MovieID) en cada RDD), en los RDDs transformados *no* uses `collect()`. No todo (UserID, MovieID) aparecerá en ambos RDDs, si un par no aparece en ambos no contribuye al RMSE. Al final terminaremos con un RDD con entradas de la forma  $ (x_i - y_i)^2$ Puedes ver en el módulo de Python [math](https://docs.python.org/2/library/math.html) como se calculan estos valores.\n",
    "\n",
    "* #### Utilizando un acción RDD (**no** `collect()`), calcula el error cuadrático total $ SE = \\sum_{i = 1}^{n} (x_i - y_i)^2 $\n",
    "* #### Calcula *n* pero utilizando una acción RDD (que no sea `collect()` ) para contar el número de pares para los que se han calculado el error cuadrático total\n",
    "* #### Usando el error cuadrático total y el número de pares, calcula el RSME. Asegúrate de calcular este valor como un [float](https://docs.python.org/2/library/stdtypes.html#numeric-types-int-float-long-complex)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error para el dataset de test (debería ser 1.22474487139): 1.22474487139\n",
      "Error para el dataset2 de test (debería ser 3.16227766017): 3.16227766017\n",
      "Error para testActual dataset (debería ser 0.0): 0.0\n"
     ]
    }
   ],
   "source": [
    "# TODO: Sustituye <RELLENA> con código apropiado\n",
    "import math\n",
    "\n",
    "def computeError(predictedRDD, actualRDD):\n",
    "    \"\"\" Calcula el error cuadrático medio entre los predichos y los reales\n",
    "    Args:\n",
    "        predictedRDD: ratings predichos para cada peli y cada usuario donde cada entrada tiene la forma\n",
    "                      (UserID, MovieID, Rating)\n",
    "        actualRDD: ratings reales donde cada entrada tiene la forma (UserID, MovieID, Rating)\n",
    "    Returns:\n",
    "        RSME (float): valor RSME calculado\n",
    "    \"\"\"\n",
    "    # Transforma predictedRDD en tuplas ((UserID, MovieID), Rating)\n",
    "    predictedReformattedRDD = predictedRDD.map (lambda (userID, movieID, rating): ((userID,movieID), rating))\n",
    "\n",
    "    # Transforma actualRDD en tuplas ((UserID, MovieID), Rating)\n",
    "    actualReformattedRDD = actualRDD.map (lambda (userID, movieID, rating): ((userID,movieID), rating))\n",
    "\n",
    "    # Calcula el error cuadrático para cada entrada que haga matching: mismo (User ID, Movie ID) en cada\n",
    "    # RDD) \n",
    "    squaredErrorsRDD = predictedReformattedRDD.join (actualReformattedRDD).map (lambda rec: (rec[1][0] - rec[1][1]) * (rec[1][0]-rec[1][1]))\n",
    "\n",
    "    # Calcula el error cuadrático total\n",
    "    totalError = squaredErrorsRDD.reduce (lambda a, b: a + b)\n",
    "\n",
    "    # Cuenta el número de entradas para las que se ha calculado el error cuadrático total\n",
    "    numRatings = squaredErrorsRDD.count()\n",
    "\n",
    "    # calcula el RSME\n",
    "    return math.sqrt(float(totalError) / numRatings)\n",
    "\n",
    "\n",
    "# sc.parallelize nos devuelve una lista de Python en un RDD.\n",
    "testPredicted = sc.parallelize([\n",
    "    (1, 1, 5),\n",
    "    (1, 2, 3),\n",
    "    (1, 3, 4),\n",
    "    (2, 1, 3),\n",
    "    (2, 2, 2),\n",
    "    (2, 3, 4)])\n",
    "testActual = sc.parallelize([\n",
    "     (1, 2, 3),\n",
    "     (1, 3, 5),\n",
    "     (2, 1, 5),\n",
    "     (2, 2, 1)])\n",
    "testPredicted2 = sc.parallelize([\n",
    "     (2, 2, 5),\n",
    "     (1, 2, 5)])\n",
    "testError = computeError(testPredicted, testActual)\n",
    "print 'Error para el dataset de test (debería ser 1.22474487139): %s' % testError\n",
    "\n",
    "testError2 = computeError(testPredicted2, testActual)\n",
    "print 'Error para el dataset2 de test (debería ser 3.16227766017): %s' % testError2\n",
    "\n",
    "testError3 = computeError(testActual, testActual)\n",
    "print 'Error para testActual dataset (debería ser 0.0): %s' % testError3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Root Mean Square Error (2b)\n",
    "Test.assertTrue(abs(testError - 1.22474487139) < 0.00000001,\n",
    "                'testError incorrecto (esperado 1.22474487139)')\n",
    "Test.assertTrue(abs(testError2 - 3.16227766017) < 0.00000001,\n",
    "                'testError2 incorrecto  result (esperado 3.16227766017)')\n",
    "Test.assertTrue(abs(testError3 - 0.0) < 0.00000001,\n",
    "                'testActual incorrecto result (esperado 0.0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2c) Usando ALS.train()**\n",
    "#### En esta parte usaremos la implementación de MLlib de mínimos cuadrados alternos  [ALS.train()](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.recommendation.ALS). ALS toma un training dataset (RDD) y varios parámetros que controla el proceso de creación del modelo. Para determinar los mejores valores para los parámetros usaremos ALS para entrenar varios modelos, selecionaremos el mejor modelo y usaremos los parámetros de ese modelo en el resto de los ejercicios del lab.\n",
    "#### El proceso que usaremos para determinar el mejor modelo sera:\n",
    "* #### Seleccionar un conjunto de parámetros para el modelo. El parámetro más importante en `ALS.train()` es el *rank* que es el número de filas en la matriz de usuarios (en verde en el diagrama) o el numero de columnas en la matriz de pelis (azul en el diagrama). En general, un rank bajo significará errores grandes en el dataset de training, pero un rank alto puede pecar de [overfitting](https://en.wikipedia.org/wiki/Overfitting).) Usaremos ranks de 4, 8 y 12 utilizando el `trainingRDD` dataset.\n",
    "* #### Crear un modelo utilizando `ALS.train(trainingRDD, rank, seed=seed, iterations=iterations, lambda_=regularizationParameter)` con tres parámetros: un RDD de tuplas de la forma (UserID, MovieID, rating) utilizado para entrenar el modelo, un rank de enteros (4, 8 ó 12), un número de iteraciones a ejecutar (usaremos 5 para el parámetro `iterations`) y un coeficiente de regularización (usaremos 0.1 para `regularizationParameter`).\n",
    "* #### Para el paso de predición, crearemos un RDD de entrada `validationForPredictRDD`, formado por pares (UserID, MovieID) que se extraen de `validationRDD`. Al finalizar tendremos un RDD de la forma: `[(1, 1287), (1, 594), (1, 1270)]`\n",
    "* #### Utilizando el modelo y `validationForPredictRDD`, podemos predecir rating llamando a [model.predictAll()](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.recommendation.MatrixFactorizationModel.predictAll) con el  `validationForPredictRDD` dataset, donde `model` es el modelo que se genera con ALS.train(). `predictAll` acepta un RDD con entradas de la forma (userID, movieID) y devuelve un RDD con cada entrada en la forma (userID, movieID, rating).\n",
    "* #### Evaluaremos la calidad del modelo utilizando la función `computeError()` del apartado (2b) para calcular el error entre los ratings predichos y los ratings reales de `validationRDD`.\n",
    "####  ¿Qué rank es el que produce el mejor modelo según RMSE con el dataset  `validationRDD`?\n",
    "#### La operación llevará su tiempo (puedes observar el progreso con [Spark Web UI](http://localhost:4040). La mayor parte es para ejecutar la función `computeError()` ya que a diferencia de la implementación de ALS (y el módulo de Spark 1.4  [RegressionMetrics](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.evaluation.RegressionMetrics) ), no utiliza una librería rápida de álgebra linear y necesita ejecutar el código Phyton para todas las 100k entradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para el rank 4 el RMSE es 0.892734779484\n",
      "para el rank 8 el RMSE es 0.890121292255\n",
      "para el rank 12 el RMSE es 0.890216118367\n",
      "The best model was trained with rank 8\n"
     ]
    }
   ],
   "source": [
    "# TODO: Sustituye <RELLENA> con código apropiado\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "\n",
    "validationForPredictRDD = validationRDD.map (lambda (userId, movieId, rating) : (userId, movieId) )\n",
    "\n",
    "\n",
    "seed = 5L\n",
    "iterations = 5\n",
    "regularizationParameter = 0.1\n",
    "ranks = [4, 8, 12]\n",
    "errors = [0, 0, 0]\n",
    "err = 0\n",
    "tolerance = 0.03\n",
    "\n",
    "minError = float('inf')\n",
    "bestRank = -1\n",
    "bestIteration = -1\n",
    "for rank in ranks:\n",
    "    model = ALS.train(trainingRDD, rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularizationParameter)\n",
    "    predictedRatingsRDD = model.predictAll(validationForPredictRDD)\n",
    "    error = computeError(predictedRatingsRDD, validationRDD)\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    print 'para el rank %s el RMSE es %s' % (rank, error)\n",
    "    if error < minError:\n",
    "        minError = error\n",
    "        bestRank = rank\n",
    "\n",
    "print 'The best model was trained with rank %s' % bestRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Uso de ALS.train (2c)\n",
    "Test.assertEquals(trainingRDD.getNumPartitions(), 2,\n",
    "                  'número incorrecto de particiones para trainingRDD (se esperaban 2)')\n",
    "Test.assertEquals(validationForPredictRDD.count(), 96902,\n",
    "                  'tamaño incorrecto para validationForPredictRDD (se esperaba 96902)')\n",
    "Test.assertEquals(validationForPredictRDD.filter(lambda t: t == (1, 1907)).count(), 1,\n",
    "                  'valor incorrecto para validationForPredictRDD')\n",
    "Test.assertTrue(abs(errors[0] - 0.883710109497) < tolerance, 'errors[0] incorrecto')\n",
    "Test.assertTrue(abs(errors[1] - 0.878486305621) < tolerance, 'errors[1] incorrecto')\n",
    "Test.assertTrue(abs(errors[2] - 0.876832795659) < tolerance, 'errors[2] incorrecto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2d) Testeo del modelo**\n",
    "#### Hemos usado los datasets `trainingRDD` y `validationRDD` para seleccionar el mejor model por lo que no podemos utilizarlos para saber como de bueno es nuestro model ya que podría ser muy vulnerable al [overfitting](https://en.wikipedia.org/wiki/Overfitting).  Es por eso que necesitamos usar el dataset `testRDD`. Utilizaremos el `bestRank` del apartado (2c) para crear un modelo para predecir los ratings para el dataset de test y calcular el RMSE.\n",
    "\n",
    "#### Los pasos a dar son:\n",
    "* #### Entrenar un modelo utilizando `trainingRDD`, `bestRank` y los parámetros que has usado en (2c): `seed=seed`, `iterations=iterations`, y `lambda_=regularizationParameter` - asegúrate que incluyes **todos** los parámetros.\n",
    "* #### Para los pasos de predicción crea un RDD de entrada, `testForPredictingRDD`, con pares de la forma (UserID, MovieID) que extraigas de `testRDD`. Tendras que tener un RDD de la forma: `[(1, 1287), (1, 594), (1, 1270)]`\n",
    "* #### Usa [myModel.predictAll()](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.recommendation.MatrixFactorizationModel.predictAll) para predecir los valores par el dataset de test.\n",
    "* #### Para evaluar la calidad del modelo utiliza `testRDD` y la función `computeError` para calcular el error RMSE entre `testRDD` y `predictedTestRDD`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo tiene un RMSE en el conjunto de test de 0.891048561304\n"
     ]
    }
   ],
   "source": [
    "# TODO: Sustituye <RELLENA> con código apropiado\n",
    "myModel = ALS.train(trainingRDD, bestRank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularizationParameter)\n",
    "testForPredictingRDD = testRDD.map (lambda (userId, movieId, rating): (userId, movieId))\n",
    "predictedTestRDD = myModel.predictAll(testForPredictingRDD)\n",
    "\n",
    "\n",
    "testRMSE = computeError(testRDD, predictedTestRDD)\n",
    "\n",
    "print 'El modelo tiene un RMSE en el conjunto de test de %s' % testRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Testeo de tu modelo (2d)\n",
    "Test.assertTrue(abs(testRMSE - 0.87809838344) < tolerance, 'testRMSE incorrecto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2e)Comparando el modelo**\n",
    "#### Mirar el RMSE para los resultados predichos por el modelo vs los valores en el set de test es una forma de evaluar la calidad de nuestro modelo. Otra forma de evaluarlo es evaluar el error de un conjunto de test donde cada rating es la media para ese training set.\n",
    "#### Los pasos a dar son:\n",
    "* #### Usa `trainingRDD` para calcular la media de todas las pelis el dataset de training.\n",
    "* #### Usa el rating medio que has determinado y el `testRDD` para crear un RDD con entradas de la forma  (userID, movieID, average rating).\n",
    "* #### Usa la función `computeError` para calcular el RMSE entre el `testRDD` de validación que has creado y el  `testForAvgRDD`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average rating for movies in the training set is 3.57409571052\n",
      "The RMSE on the average set is 1.12036693569\n"
     ]
    }
   ],
   "source": [
    "# TODO: Sustituye <RELLENA> con código apropiado\n",
    "\n",
    "trainingAvgRating = trainingRDD.map (lambda (user, movie, rating):rating).mean()\n",
    "print 'The average rating for movies in the training set is %s' % trainingAvgRating\n",
    "\n",
    "testForAvgRDD = testRDD.map (lambda (user, movie, rating):(user,movie,trainingAvgRating))\n",
    "testAvgRMSE = computeError(testRDD, testForAvgRDD)\n",
    "print 'The RMSE on the average set is %s' % testAvgRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Comparando el model (2e)\n",
    "Test.assertTrue(abs(trainingAvgRating - 3.57409571052) < 0.000001,\n",
    "                'trainingAvgRating incorrecto (esperado 3.57409571052)')\n",
    "Test.assertTrue(abs(testAvgRMSE - 1.12036693569) < 0.000001,\n",
    "                'testAvgRMSE incorrecto (esperado 1.12036693569)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¡Ahora ya podemos realizar prediciones de como los usuarios calificarán las pelis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 3: Prediciones para ti**\n",
    "#### Por último vamos a hacer recomendaciones para nosotros mismos. Para ello necesitamos añadir ratings personales al  `ratingsRDD` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3a) Tus ratings de pelis**\n",
    "#### Para ayudarte a proporcionar ratings, tenemos el siguiente código que lista los nombres y los IDs de las 50 pelis con la calificaciones más altas de `movieLimitedAndSortedByRatingRDD` que creamos en la parte 1 del lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pelis más calificadas:\n",
      "(media de calificación, nombre de la peli, número de califiaciones)\n",
      "(4.5349264705882355, u'Shawshank Redemption, The (1994)', 1088)\n",
      "(4.515798462852263, u\"Schindler's List (1993)\", 1171)\n",
      "(4.512893982808023, u'Godfather, The (1972)', 1047)\n",
      "(4.510460251046025, u'Raiders of the Lost Ark (1981)', 1195)\n",
      "(4.505415162454874, u'Usual Suspects, The (1995)', 831)\n",
      "(4.457256461232604, u'Rear Window (1954)', 503)\n",
      "(4.45468509984639, u'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)', 651)\n",
      "(4.43953006219765, u'Star Wars: Episode IV - A New Hope (1977)', 1447)\n",
      "(4.4, u'Sixth Sense, The (1999)', 1110)\n",
      "(4.394285714285714, u'North by Northwest (1959)', 700)\n",
      "(4.379506641366224, u'Citizen Kane (1941)', 527)\n",
      "(4.375, u'Casablanca (1942)', 776)\n",
      "(4.363975155279503, u'Godfather: Part II, The (1974)', 805)\n",
      "(4.358816276202219, u\"One Flew Over the Cuckoo's Nest (1975)\", 811)\n",
      "(4.358173076923077, u'Silence of the Lambs, The (1991)', 1248)\n",
      "(4.335826477187734, u'Saving Private Ryan (1998)', 1337)\n",
      "(4.326241134751773, u'Chinatown (1974)', 564)\n",
      "(4.325383304940375, u'Life Is Beautiful (La Vita \\ufffd bella) (1997)', 587)\n",
      "(4.324110671936759, u'Monty Python and the Holy Grail (1974)', 759)\n",
      "(4.3096, u'Matrix, The (1999)', 1250)\n",
      "(4.309457579972183, u'Star Wars: Episode V - The Empire Strikes Back (1980)', 1438)\n",
      "(4.30379746835443, u'Young Frankenstein (1974)', 553)\n",
      "(4.301346801346801, u'Psycho (1960)', 594)\n",
      "(4.296438883541867, u'Pulp Fiction (1994)', 1039)\n",
      "(4.286535303776683, u'Fargo (1996)', 1218)\n",
      "(4.282367447595561, u'GoodFellas (1990)', 811)\n",
      "(4.27943661971831, u'American Beauty (1999)', 1775)\n",
      "(4.268053855569155, u'Wizard of Oz, The (1939)', 817)\n",
      "(4.267774699907664, u'Princess Bride, The (1987)', 1083)\n",
      "(4.253333333333333, u'Graduate, The (1967)', 600)\n",
      "(4.236263736263736, u'Run Lola Run (Lola rennt) (1998)', 546)\n",
      "(4.233807266982622, u'Amadeus (1984)', 633)\n",
      "(4.232558139534884, u'Toy Story 2 (1999)', 860)\n",
      "(4.232558139534884, u'This Is Spinal Tap (1984)', 516)\n",
      "(4.228494623655914, u'Almost Famous (2000)', 744)\n",
      "(4.2250755287009065, u'Christmas Story, A (1983)', 662)\n",
      "(4.216757741347905, u'Glory (1989)', 549)\n",
      "(4.213358070500927, u'Apocalypse Now (1979)', 539)\n",
      "(4.20992028343667, u'L.A. Confidential (1997)', 1129)\n",
      "(4.204733727810651, u'Blade Runner (1982)', 845)\n",
      "(4.1886120996441285, u'Sling Blade (1996)', 562)\n",
      "(4.184615384615385, u'Braveheart (1995)', 1300)\n",
      "(4.184168012924071, u'Butch Cassidy and the Sundance Kid (1969)', 619)\n",
      "(4.182509505703422, u'Good Will Hunting (1997)', 789)\n",
      "(4.166969147005445, u'Taxi Driver (1976)', 551)\n",
      "(4.162767039674466, u'Terminator, The (1984)', 983)\n",
      "(4.157545605306799, u'Reservoir Dogs (1992)', 603)\n",
      "(4.153333333333333, u'Jaws (1975)', 750)\n",
      "(4.149840595111583, u'Alien (1979)', 941)\n",
      "(4.145015105740181, u'Toy Story (1995)', 993)\n"
     ]
    }
   ],
   "source": [
    "print 'Pelis más calificadas:'\n",
    "print '(media de calificación, nombre de la peli, número de califiaciones)'\n",
    "for ratingsTuple in movieLimitedAndSortedByRatingRDD.take(50):\n",
    "    print ratingsTuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El user ID 0 no está asignado, asi que lo usaremos para nuestros ratings utilizando la variable `myUserID`. A continuación creamos un nuevo RDD  `myRatingsRDD` con tus ratings para al menos 10 pelis. cada entrada debería estar formateada como `(myUserID, movieID, rating)` (de la misma manera que `trainingRDD`) y como el dataset original los ratings deberían estar entre 1 y 5 (incluidos). Si no has visto al menos 10 de las pelis del listado puedes incrementar el parámetro `take()` hasta que haya 10 películas que hayas visto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratings de mis pelis: [(0, 260, 5), (0, 261, 4), (0, 262, 3), (0, 263, 3), (0, 264, 2), (0, 265, 1), (0, 266, 5), (0, 267, 4), (0, 268, 3), (0, 269, 1)]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Sustituye <RELLENA> con código apropiado\n",
    "myUserID = 0\n",
    "\n",
    "# No confundas el rating con el movie ID!!!.\n",
    "myRatedMovies = [\n",
    "     (myUserID, 260, 5),(myUserID, 261, 4),(myUserID, 262, 3),(myUserID, 263, 3),(myUserID, 264, 2),(myUserID, 265, 1),\n",
    "    (myUserID, 266, 5),(myUserID, 267, 4),(myUserID, 268, 3),(myUserID, 269, 1)\n",
    "\n",
    "     # El formato de cada línea es (myUserID, movie ID, your rating)\n",
    "     # Ejemplo \"Star Wars: Episode IV - A New Hope (1977)\" con un rating de 5 se añadiría como:\n",
    "     #   (myUserID, 260, 5),\n",
    "    ]\n",
    "myRatingsRDD = sc.parallelize(myRatedMovies)\n",
    "print 'ratings de mis pelis: %s' % myRatingsRDD.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3b) Añade tus pelis al Training Dataset**\n",
    "#### Ahor que tienes ratins para ti mismo, necesitas añadir tus ratings al dataset de `training` de tal forma que el modelo a entrenar incorpore tus preferencias. La transformación de Spark [union()](http://spark.apache.org/docs/latest/api/python/pyspark.rdd.RDD-class.html#union) combina dos RDDs. Utilizalá para crear un nuevo dataset de training con los datos originales y tus preferencias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset now has 10 more entries than the original training dataset\n"
     ]
    }
   ],
   "source": [
    "# TODO: Sustituye <RELLENA> con código apropiado\n",
    "trainingWithMyRatingsRDD = trainingRDD.union (myRatingsRDD)\n",
    "\n",
    "print ('The training dataset now has %s more entries than the original training dataset' %\n",
    "       (trainingWithMyRatingsRDD.count() - trainingRDD.count()))\n",
    "assert (trainingWithMyRatingsRDD.count() - trainingRDD.count()) == myRatingsRDD.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3c) Entrenar un modelo con tus ratings**\n",
    "#### Ahora entrena un modelo con tus ratings añadidos y los parámetros que usamos en la parte (2c): `bestRank`, `seed=seed`, `iterations=iterations`, y `lambda_=regularizationParameter` - asegúrate de que incluyes **todos** los parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Sustituye <RELLENA> con código apropiado\n",
    "myRatingsModel = ALS.train(trainingWithMyRatingsRDD, bestRank,  seed=seed, iterations=iterations,\n",
    "                      lambda_=regularizationParameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3d) Comprobar el RMSE para el nuevo modelo con tus ratings**\n",
    "#### Calcular el RMSE para este nuevo modelo en el set de test.\n",
    "* #### Para el paso de predicción reusamos `testForPredictingRDD`, con pares (UserID, MovieID) que hemos extraido de `testRDD`. El RDD tiene la forma `[(1, 1287), (1, 594), (1, 1270)]`\n",
    "* #### Usa `myRatingsModel.predictAll()` para predecir los ratings para el dataset de test `testForPredictingRDD` y llámalo `predictedTestMyRatingsRDD`\n",
    "* #### Para validar usa `testRDD` y la función `computeError` para calcular el RMSE entre `testRDD` y `predictedTestMyRatingsRDD` del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo tiene un RMSE con el conjunto de test de 0.891995030395\n"
     ]
    }
   ],
   "source": [
    "# TODO: Sustituye <RELLENA> con código apropiado\n",
    "predictedTestMyRatingsRDD = myRatingsModel.predictAll (testForPredictingRDD)\n",
    "testRMSEMyRatings = computeError (testRDD, predictedTestMyRatingsRDD)\n",
    "print 'El modelo tiene un RMSE con el conjunto de test de %s' % testRMSEMyRatings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3e) Predecir tus calificaciones **\n",
    "#### Hasta el momento solo hemos utilizado el método  `predictAll` para calcular el error del modelo. Ahora vamos a usar `predictAll` para predecir que ratings darías a pelis que aún no has calificado.\n",
    "#### Los pasos a dar son:\n",
    "* #### Usa la lista de Python `myRatedMovies` para transformar `moviesRDD`en un RDD cuyas entradas son pares de la forma (myUserID, Movie ID) y no contienen ninguna película que hayas calificado. Esta transformación devolverá un RDD de la forma: `[(0, 1), (0, 2), (0, 3), (0, 4)]`. Puedes hacer este paso con una única transformación RDD.\n",
    "* #### Para el paso de predición utiliza el RDD de entrada `myUnratedMoviesRDD` con myRatingsModel.predictAll() para predecir tus calificaciones para las pelis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Sustituye <RELLENA> con código apropiado\n",
    "\n",
    "# Usa la lista de Python myRatedMovies para transformar moviesRDD en un RDD con entradas tipo (myUserID, Movie ID) \n",
    "# y que no contengasn ninguna peli que hayas calificado.\n",
    "myUnratedMoviesRDD = (moviesRDD.map (lambda (movieId, movieTitle): (0,movieId)))\n",
    "\n",
    "# usa myUnratedMoviesRDD con myRatingsModel.predictAll() para predecir los ratings sobre las pelis.\n",
    "predictedRatingsRDD = myRatingsModel.predictAll (myUnratedMoviesRDD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3f) Predecir tus calificaciones (2)**\n",
    "#### Con los ratings predichos podemos imprimir las 25 pelis con la calificación más alta.\n",
    "#### Los pasos a dar son:\n",
    "* #### Por los apartados (1b) y (1c) sabemos que deberíamos sólo tener en cuenta pelis con un número razonable de reviews (por ejemplo, más de 75). Podemos experimentar con límites más bajos pero pocos ratings para una peli harán que tengamos más errores en la predicción. Transforma `movieIDsWithAvgRatingsRDD` del apartado (1b) que tiene la forma  (MovieID, (number of ratings, average rating)) en un RDD de la forma (MovieID, number of ratings): `[(2, 332), (4, 71), (6, 442)]`\n",
    "* #### Queremos ver los nombres de las pelis en vez de los IDs, asi que transformaremos `predictedRatingsRDD` en un RDD con entradas de la forma (Movie ID, Predicted Rating): `[(3456, -0.5501005376936687), (1080, 1.5885892024487962), (320, -3.7952255522487865)]`\n",
    "* #### Usa transformaciones RDD sobre `predictedRDD` y `movieCountsRDD` para devolver un un RDD con tuplas de la forma (Movie ID, (Predicted Rating, number of ratings)): `[(2050, (0.6694097486155939, 44)), (10, (5.29762541533513, 418)), (2060, (0.5055259373841172, 97))]`\n",
    "* #### Usa transformaciones RDD sobre `predictedWithCountsRDD` y `moviesRDD` para devolver un RDD con tuplas de la forma (Predicted Rating, Movie Name, number of ratings), _para pelis con más de 75 ratings_ Por ejemplo: `[(7.983121900375243, u'Under Siege (1992)'), (7.9769201864261285, u'Fifth Element, The (1997)')]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mis pelis predichas con mayores calificaciones (para pelis con más de 75 reviews):\n",
      "(3952, ((3.29318936094958, 316), u'Contender, The (2000)'))\n",
      "(3949, ((2.384084749668364, 214), u'Requiem for a Dream (2000)'))\n",
      "(3948, ((3.4670776711437847, 665), u'Meet the Parents (2000)'))\n",
      "(3946, ((1.4173383391462544, 83), u'Get Carter (2000)'))\n",
      "(3937, ((2.5400325254619727, 115), u'Runaway (1984)'))\n",
      "(3936, ((3.5786851172724727, 99), u'Phantom of the Opera, The (1943)'))\n",
      "(3932, ((2.215342917195037, 202), u'Invisible Man, The (1933)'))\n",
      "(3930, ((1.6745750714646945, 197), u'Creature From the Black Lagoon, The (1954)'))\n",
      "(3929, ((2.801122225470703, 128), u'Bank Dick, The (1940)'))\n",
      "(3928, ((2.655097852785038, 178), u'Abbott and Costello Meet Frankenstein (1948)'))\n",
      "(3927, ((2.4762382438474844, 300), u'Fantastic Voyage (1966)'))\n",
      "(3926, ((2.42046290776284, 154), u'Voyage to the Bottom of the Sea (1961)'))\n",
      "(3925, ((1.246914226131255, 100), u'Stranger Than Paradise (1984)'))\n",
      "(3923, ((1.2987791269204394, 91), u'Return of the Fly (1959)'))\n",
      "(3918, ((1.4224025652779917, 145), u'Hellbound: Hellraiser II (1988)'))\n",
      "(3917, ((1.9774241790794844, 231), u'Hellraiser (1987)'))\n",
      "(3916, ((4.506495700894495, 344), u'Remember the Titans (2000)'))\n",
      "(3915, ((3.074001277037923, 96), u'Girlfight (2000)'))\n",
      "(3911, ((3.2844574630000607, 492), u'Best in Show (2000)'))\n",
      "(3910, ((1.261663833995466, 159), u'Dancer in the Dark (2000)'))\n"
     ]
    }
   ],
   "source": [
    "# TODO: Sustituye <RELLENA> con código apropiado\n",
    "\n",
    "# Transforma movieIDsWithAvgRatingsRDD del apartado (1b), con la forma \n",
    "#(MovieID, (number of ratings, average rating)), en un RDD con la forma MovieID, number of ratings)\n",
    "movieCountsRDD = movieIDsWithAvgRatingsRDD.map (lambda (movieId, (numbRatings, avgRatings)): (movieId, numbRatings))\n",
    "\n",
    "# Transforma predictedRatingsRDD en un RDD cuyas entradas son pares (Movie ID, Predicted Rating)\n",
    "predictedRDD = predictedRatingsRDD.map (lambda (userId, movieId, rating): (movieId, rating))\n",
    "\n",
    "# Usa transformaciones RDD con predictedRDD y movieCountsRDD para devolver un RDD con tuplas de la forma\n",
    "#(Movie ID, (Predicted Rating, number of ratings))\n",
    "predictedWithCountsRDD  = predictedWithCountsRDD  = predictedRDD.join (movieCountsRDD)\n",
    "\n",
    "\n",
    "# Usa transformaciones RDD con PredictedWithCountsRDD y moviesRDD para devolver un RDD con tuplas de la forma\n",
    "#(Predicted Rating, Movie Name, number of ratings), para pelis con más de 75 ratings\n",
    "ratingsWithNamesRDD = predictedWithCountsRDD.join (moviesRDD).filter (lambda (movieId,((rating,numRatings),title)): numRatings > 75)\n",
    "\n",
    "predictedHighestRatedMovies = ratingsWithNamesRDD.takeOrdered(20, key=lambda x: -x[0])\n",
    "print ('Mis pelis predichas con mayores calificaciones (para pelis con más de 75 reviews):\\n%s' %\n",
    "        '\\n'.join(map(str, predictedHighestRatedMovies)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
