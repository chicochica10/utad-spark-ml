{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ML Logo](https://raw.githubusercontent.com/chicochica10/utad-spark-ml/master/images/utad-spark-ml.1x_Banner_300.png)\n",
    "# **Lab de Regresión lineal**\n",
    "#### Este lab cubre un pipeline común de aprendizaje supervisado, usando un subconjunto de [Million Song Dataset](http://labrosa.ee.columbia.edu/millionsong/) de [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/YearPredictionMSD). Nuestro objetivo será entrenar un modelo de regresión lineal para predecir el año de una canción dado un conjunto de características de audio.\n",
    "#### ** Este lab cubre: **\n",
    "+  ####*Parte 1:* Leer y parsear el dataset inicial\n",
    " + #### *Visualización 1:* Características\n",
    " + #### *Visualización 2:* Cambiando etiquetas\n",
    "+  ####*Parte 2:* Crear y evaluar un modelo baseline\n",
    " + #### *Visualización 3:* Predicho vs. real\n",
    "+  ####*Parte 3:* Entrenamiento (via descenso del gradiente) y evaluación del modelo de regresión lineal\n",
    " + #### *Visualización 4:* Error de entrenamiento\n",
    "+  ####*Parte 4:* Entrenamiento usando MLib y ajuste de hiperparámetros via búsqueda en grid\n",
    " + #### *Visualización 5:* Prediciones del mejor modelo\n",
    " + #### *Visualización 6:* Mapa de calor de hiperparámetros\n",
    "+  ####*Parte 5:* Añadir interacciones entre características\n",
    " \n",
    "####  Como referencia puedes mirar el api de Spark en  [API de Spark Python](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD) y los métodos de NumPy en [Referencia NumPy](http://docs.scipy.org/doc/numpy/reference/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Parte 1: Leer y parsear el dataset inicial **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (1a) Cargar y comprobar los datos **\n",
    "#### Los datos en bruto están almacenados en un fichero de texto, empezaremos por cargarlos en un RDD, cada elemento de un RDD representa un \"data point\" reflejado como un string delimitado por comas. Cada string comienza con la etiqueta (label) que es un año seguido de unas características numéricas de audio. Utiliza el [método count](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.count) para comprobar cuantos \"data points\" tenemos. Usa el [método take](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.take) para imprimir 5 \"data points\" en su formato inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# carga de librería de testing\n",
    "from test_helper import Test\n",
    "import os.path\n",
    "baseDir = os.path.join('data')\n",
    "inputPath = os.path.join('utad-spark-ml', 'millionsong.txt')\n",
    "fileName = os.path.join(baseDir, inputPath)\n",
    "\n",
    "numPartitions = 2\n",
    "rawData = sc.textFile(fileName, numPartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Sustituye <RELLENA> con el código apropiado\n",
    "numPoints = <RELLENA>\n",
    "print numPoints\n",
    "samplePoints = <RELLENA>\n",
    "print samplePoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Carga y comprobación de los datos (1a)\n",
    "Test.assertEquals(numPoints, 6724, 'valor incorrecto para numPoints')\n",
    "Test.assertEquals(len(samplePoints), 5, 'longitud incorrecto para samplePoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (1b) Uso de  `LabeledPoint` **\n",
    "#### En MLib las instancias de training etiquetadas se almacenan utilizando objetos [LabeledPoint](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LabeledPoint). Escribe la función de parsePoint que toma como entrada un punto de datos y lo parsea utilizando el método [unicode.split](https://docs.python.org/2/library/string.html#string.split) y devuelve un  `LabeledPoint`. Usa esta función para parsear samplePoints (del punto anterior). Imprime las características y la etiqueta para el primer training point utilizando los atributos `LabeledPoint.features` y `LabeledPoint.label`. Por último calcula el número de características para este dataset.\n",
    "\n",
    "#### Nota: `split()` se puede llamar directemente desde un objeto  `unicode` o `str`. Por ejemplo, `u'split,me'.split(',')` devuelve `[u'split', u'me']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "import numpy as np\n",
    "\n",
    "# Ejemplo de un data point:\n",
    "# '2001.0,0.884,0.610,0.600,0.474,0.247,0.357,0.344,0.33,0.600,0.425,0.60,0.419'\n",
    "#  2001.0 es la etiqueta y el resto de valores son las características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Sustituye <RELLENA> con el código apropiado\n",
    "def parsePoint(line):\n",
    "    \"\"\"Conviere un unicode string con comas por separador en un `LabeledPoint`.\n",
    "\n",
    "    Args:\n",
    "        line (unicode): unicode string con comas por separador\n",
    "        donde el primer elemento es la etiqueta y el resto son características \n",
    "\n",
    "    Returns:\n",
    "        LabeledPoint: La linea convertida en un `LabeledPoint` que consiste en una etiqueta y características\n",
    "    \"\"\"\n",
    "    <RELLENA>\n",
    "\n",
    "parsedSamplePoints = <RELLENA>\n",
    "firstPointFeatures = <RELLENA>\n",
    "firstPointLabel = <RELLENA>\n",
    "print firstPointFeatures, firstPointLabel\n",
    "\n",
    "d = len(firstPointFeatures)\n",
    "print d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Usando LabeledPoint (1b)\n",
    "Test.assertTrue(isinstance(firstPointLabel, float), 'La etiqueta debe ser un float')\n",
    "expectedX0 = [0.8841,0.6105,0.6005,0.4747,0.2472,0.3573,0.3441,0.3396,0.6009,0.4257,0.6049,0.4192]\n",
    "Test.assertTrue(np.allclose(expectedX0, firstPointFeatures, 1e-4, 1e-4),\n",
    "                'características incorrectas para firstPointFeatures')\n",
    "Test.assertTrue(np.allclose(2001.0, firstPointLabel), 'etiqueta incorrecta para firstPointLabel')\n",
    "Test.assertTrue(d == 12, 'número de características incorrecto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Visualización 1: Características**\n",
    "#### Primero cargaremos y arrancaremos la librería de visualizacion después tomaremos las características de 50 puntos generando un mapa de calor que visualiza cada característica en una escala de grises y muestra la variación de cada característica en esos 50 puntos de muestra. Las características estarán entre 0 y 1. Los valores más cercanos a 1 son más oscuros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "sampleMorePoints = rawData.take(50)\n",
    "# Puedes descomentar la línea de debajo para seleccionar características aleatorias cada vez que ejecutes la celda\n",
    "# sampleMorePoints = rawData.takeSample(False, 50)\n",
    "\n",
    "parsedSampleMorePoints = map(parsePoint, sampleMorePoints)\n",
    "dataValues = map(lambda lp: lp.features.toArray(), parsedSampleMorePoints)\n",
    "\n",
    "def preparePlot(xticks, yticks, figsize=(10.5, 6), hideLabels=False, gridColor='#999999',\n",
    "                gridWidth=1.0):\n",
    "    \"\"\"Plantilla para generar el layout del plot.\"\"\"\n",
    "    plt.close()\n",
    "    fig, ax = plt.subplots(figsize=figsize, facecolor='white', edgecolor='white')\n",
    "    ax.axes.tick_params(labelcolor='#999999', labelsize='10')\n",
    "    for axis, ticks in [(ax.get_xaxis(), xticks), (ax.get_yaxis(), yticks)]:\n",
    "        axis.set_ticks_position('none')\n",
    "        axis.set_ticks(ticks)\n",
    "        axis.label.set_color('#999999')\n",
    "        if hideLabels: axis.set_ticklabels([])\n",
    "    plt.grid(color=gridColor, linewidth=gridWidth, linestyle='-')\n",
    "    map(lambda position: ax.spines[position].set_visible(False), ['bottom', 'top', 'left', 'right'])\n",
    "    return fig, ax\n",
    "\n",
    "# generar el layout y plotear\n",
    "fig, ax = preparePlot(np.arange(.5, 11, 1), np.arange(.5, 49, 1), figsize=(8,7), hideLabels=True,\n",
    "                      gridColor='#eeeeee', gridWidth=1.1)\n",
    "image = plt.imshow(dataValues,interpolation='nearest', aspect='auto', cmap=cm.Greys)\n",
    "for x, y, s in zip(np.arange(-.125, 12, 1), np.repeat(-.75, 12), [str(x) for x in range(12)]):\n",
    "    plt.text(x, y, s, color='#999999', size='10')\n",
    "plt.text(4.7, -3, 'Feature', color='#999999', size='11'), ax.set_ylabel('Observation')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1c) Encontrar el rango **\n",
    "#### Vamos a examinar las etiquetas para encontrar el rango de los años de las canciones, para hacer esto parsea primero cada elemento del RDD `rawData` y después encuentra las etiquetas mayor y menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Sustituye <RELLENA> con el código apropiado\n",
    "parsedDataInit = rawData.map(<RELLENA>)\n",
    "onlyLabels = parsedDataInit.map(<RELLENA>)\n",
    "minYear = <RELLENA>\n",
    "maxYear = <RELLENA>\n",
    "print maxYear, minYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Encuentra el rango (1c)\n",
    "Test.assertEquals(len(parsedDataInit.take(1)[0].features), 12,\n",
    "                  'número de características incorrectas en el sample point')\n",
    "sumFeatTwo = parsedDataInit.map(lambda lp: lp.features[2]).sum()\n",
    "Test.assertTrue(np.allclose(sumFeatTwo, 3158.96224351), 'parsedDataInit tiene valores incorrectos')\n",
    "yearRange = maxYear - minYear\n",
    "Test.assertTrue(yearRange == 89, 'rango incorrecto entre minYear y maxYear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1d) Cambiar etiquetas **\n",
    "#### Como acabamos de ver las etiquetas están entre los años 1900 y los años 2000. En los problemas de ML es frecuente cambiar las etiquetas para que empiecen desde cero. Partiendo de  `parsedDataInit` crea un nuevo RDD de objetos  `LabeledPoint` de tal forma que la menor de las etiquetas sea igual a cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Sustituye <RELLENA> con el código apropiado\n",
    "parsedData = parsedDataInit.<RELLENA>\n",
    "\n",
    "# Debería ser un LabeledPoint\n",
    "print type(parsedData.take(1)[0])\n",
    "# ver el primer punto\n",
    "print '\\n{0}'.format(parsedData.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Cambio de etiquetas (1d)\n",
    "oldSampleFeatures = parsedDataInit.take(1)[0].features\n",
    "newSampleFeatures = parsedData.take(1)[0].features\n",
    "Test.assertTrue(np.allclose(oldSampleFeatures, newSampleFeatures),\n",
    "                'las nuevas característica no casan con las antiguas')\n",
    "sumFeatTwo = parsedData.map(lambda lp: lp.features[2]).sum()\n",
    "Test.assertTrue(np.allclose(sumFeatTwo, 3158.96224351), 'parsedData tiene valores incorrectos')\n",
    "minYearNew = parsedData.map(lambda lp: lp.label).min()\n",
    "maxYearNew = parsedData.map(lambda lp: lp.label).max()\n",
    "Test.assertTrue(minYearNew == 0, 'año mínimo incorrecto en los datos cambiados')\n",
    "Test.assertTrue(maxYearNew == 89, 'año máximo incorrecto en los datos cambiados')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** Visualización 2: Cambio de etiquetas **\n",
    "#### Vamos a echar un vistazo a las etiquetas antes y después de cambiarlas. Ambos scatter plots visualizan las tuplas que guardan i) una etiqueta y ii) el número de training point de esa etiqueta. El primer scatter plot usa las etiquetas iniciales mientras que el segundo usa las etiquetas cambiadas. Ambos plot debería ser iguales excepto por las etiquetas en el eje de las x's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# obtener los datos para el plot\n",
    "oldData = (parsedDataInit\n",
    "           .map(lambda lp: (lp.label, 1))\n",
    "           .reduceByKey(lambda x, y: x + y)\n",
    "           .collect())\n",
    "x, y = zip(*oldData)\n",
    "\n",
    "# generar el layout y hacer el plot\n",
    "fig, ax = preparePlot(np.arange(1920, 2050, 20), np.arange(0, 150, 20))\n",
    "plt.scatter(x, y, s=14**2, c='#d6ebf2', edgecolors='#8cbfd0', alpha=0.75)\n",
    "ax.set_xlabel('Year'), ax.set_ylabel('Count')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# obtener los datos para el plot\n",
    "newData = (parsedData\n",
    "           .map(lambda lp: (lp.label, 1))\n",
    "           .reduceByKey(lambda x, y: x + y)\n",
    "           .collect())\n",
    "x, y = zip(*newData)\n",
    "\n",
    "# generar el layout y hacer el plot\n",
    "fig, ax = preparePlot(np.arange(0, 120, 20), np.arange(0, 120, 20))\n",
    "plt.scatter(x, y, s=14**2, c='#d6ebf2', edgecolors='#8cbfd0', alpha=0.75)\n",
    "ax.set_xlabel('Year (shifted)'), ax.set_ylabel('Count')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (1e) Training, validación y test sets **\n",
    "#### Ya casi hemos terminado de paresear el dataset, nuestra última tarea será partirlo en los subconjuntos de training, validación y test.  Usa el  [métod randomSplit](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.randomSplit) con la semilla y los pesos especificados para crear los RDDs que almacenen estos datasets. A continuación cachéalos  ya que los vamos a acceder muchas veces a lo largo del lab. Por último calcula el tamaño de cada dataset y verifica que la suma de sus tamaños es igual al valor calculado en la parte (1a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Sustituye <RELLENA> con el código apropiado\n",
    "weights = [.8, .1, .1]\n",
    "seed = 42\n",
    "parsedTrainData, parsedValData, parsedTestData = parsedData.<RELLENA>\n",
    "parsedTrainData.<RELLENA>\n",
    "parsedValData.<RELLENA>\n",
    "parsedTestData.<RELLENA>\n",
    "nTrain = parsedTrainData.<RELLENA>\n",
    "nVal = parsedValData.<RELLENA>\n",
    "nTest = parsedTestData.<RELLENA>\n",
    "\n",
    "print nTrain, nVal, nTest, nTrain + nVal + nTest\n",
    "print parsedData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Set de training, validación, y tests (1e)\n",
    "Test.assertEquals(parsedTrainData.getNumPartitions(), numPartitions,\n",
    "                  'número incorrecto de particiones para parsedTrainData')\n",
    "Test.assertEquals(parsedValData.getNumPartitions(), numPartitions,\n",
    "                  'número incorrecto de particiones para parsedValData')\n",
    "Test.assertEquals(parsedTestData.getNumPartitions(), numPartitions,\n",
    "                  'número incorrecto de particiones para parsedTestData')\n",
    "Test.assertEquals(len(parsedTrainData.take(1)[0].features), 12,\n",
    "                  'número incorrecto de características para parsedTrainData')\n",
    "sumFeatTwo = (parsedTrainData\n",
    "              .map(lambda lp: lp.features[2])\n",
    "              .sum())\n",
    "sumFeatThree = (parsedValData\n",
    "                .map(lambda lp: lp.features[3])\n",
    "                .reduce(lambda x, y: x + y))\n",
    "sumFeatFour = (parsedTestData\n",
    "               .map(lambda lp: lp.features[4])\n",
    "               .reduce(lambda x, y: x + y))\n",
    "Test.assertTrue(np.allclose([sumFeatTwo, sumFeatThree, sumFeatFour],\n",
    "                            2526.87757656, 297.340394298, 184.235876654),\n",
    "                'los datos parseados de  Train, Val, Test tienen valores incorrectos')\n",
    "Test.assertTrue(nTrain + nVal + nTest == 6724, 'tamaño incorrecto para los datasets de Train, Val, Test')\n",
    "Test.assertEquals(nTrain, 5371, 'valor incorrecto para nTrain')\n",
    "Test.assertEquals(nVal, 682, 'valor incorrecto para nVal')\n",
    "Test.assertEquals(nTest, 671, 'valor incorrecto para nTest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Parte 2: Crear y evaluar el modelo baseline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2a) etiqueta media **\n",
    "#### Un modelo muy simple pero natural que sirva como baseline es el que siempre devuelve la misma predicción independientemente del data point dado utilizando la etiqueta de la media aritmética en el set de training como valor de predicción constante. Calcula este esta media (cambiada) para los años de la canciones en el set de training. Busca en la  [API de los RDD](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD) el método apropiado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Sustituye <RELLENA> con el código apropiado\n",
    "averageTrainYear = (parsedTrainData\n",
    "                    <RELLENA>)\n",
    "print averageTrainYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST etiqueta media aritmética (2a)\n",
    "Test.assertTrue(np.allclose(averageTrainYear, 53.9316700801),\n",
    "                'valor incorrecto para averageTrainYear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2b) Error cuadrático medio **\n",
    "#### Naturalmente queremos ver lo bien que se comporta este baseline simple. Para evaluarlo usaremos el error cuadrático medio ([RMSE](http://en.wikipedia.org/wiki/Root-mean-square_deviation)). Implementa la función que calcula el RMSE para tuplas de (label, prediction) y prueba esta función en un ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Sustituye <RELLENA> con el código apropiado\n",
    "def squaredError(label, prediction):\n",
    "    \"\"\" Calcula el error cuadrático para una única predicción\n",
    "\n",
    "    Args:\n",
    "        label (float): El valor correcto para esta predicción.\n",
    "        prediction (float): El valor predicho para esta observación.\n",
    "\n",
    "    Returns:\n",
    "        float: La diferencia entre  `label` y `prediction` al cuadrado.\n",
    "    \"\"\"\n",
    "    <RELLENA>\n",
    "\n",
    "def calcRMSE(labelsAndPreds):\n",
    "    \"\"\" Calcula el error cuadrático medio para un `RDD` de tuplas (label, prediction).\n",
    "\n",
    "    Args:\n",
    "        labelsAndPred (RDD de (float, float)): un `RDD` de tuplas (label, prediction).\n",
    "\n",
    "    Returns:\n",
    "        float: El error cuadrático medio de los errores al cuadrado.\n",
    "    \"\"\"\n",
    "    <RELLENA>\n",
    "\n",
    "labelsAndPreds = sc.parallelize([(3., 1.), (1., 2.), (2., 2.)])\n",
    "# RMSE = sqrt[((3-1)^2 + (1-2)^2 + (2-2)^2) / 3] = 1.291\n",
    "exampleRMSE = calcRMSE(labelsAndPreds)\n",
    "print exampleRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Error cuadrático medio (2b)\n",
    "Test.assertTrue(np.allclose(squaredError(3, 1), 4.), 'definición incorrecta de squaredError')\n",
    "Test.assertTrue(np.allclose(exampleRMSE, 1.29099444874), 'valor incorrecto para exampleRMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2c) RMSE de training, validación y test  **\n",
    "#### Calculemos ahora el RMSE de los sets de trainining, validación y test de nuestro modelo baseline. Para ello primero crearemos RDDs de tuplas  (label, prediction) para cada dataset y despúes llamaremos a calcRMSE. Nota que cada RMSE puede ser interpretado como el error de predicción medio para el dataset dado (en término de número de años)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Sustituye <RELLENA> con el código apropiado\n",
    "labelsAndPredsTrain = parsedTrainData.<RELLENA>\n",
    "rmseTrainBase = <RELLENA>\n",
    "\n",
    "labelsAndPredsVal = parsedValData.<RELLENA>\n",
    "rmseValBase = <RELLENA>\n",
    "\n",
    "labelsAndPredsTest = parsedTestData.<RELLENA>\n",
    "rmseTestBase = <RELLENA>\n",
    "\n",
    "print 'Baseline Train RMSE = {0:.3f}'.format(rmseTrainBase)\n",
    "print 'Baseline Validación RMSE = {0:.3f}'.format(rmseValBase)\n",
    "print 'Baseline Test RMSE = {0:.3f}'.format(rmseTestBase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST RMSE de Training, validación y test (2c)\n",
    "Test.assertTrue(np.allclose([rmseTrainBase, rmseValBase, rmseTestBase],\n",
    "                            [21.305869, 21.586452, 22.136957]), 'valor incorrecto para RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** Visualización 3: Predichos vs. reales **\n",
    "#### Visualizaremos las predicciones en el dataset de validación. Los scatter plots de abajo visualizan la tuplas que contienen el valor predicho y la etiqueta verdadera. El primer scatter plot representa la situación ideal donde  el valor predicho es el mismo que el de la etiqueta verdadera, mientras que el segundo plot usa la predicción baseline (`averageTrainYear`) para todos los valores predichos. Los puntos están codificados por color que van desde un amarillo claro cuando el valor predicho y el real son iguales hasta el rojo fuerte cuando son muy diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap, Normalize\n",
    "from matplotlib.cm import get_cmap\n",
    "cmap = get_cmap('YlOrRd')\n",
    "norm = Normalize()\n",
    "\n",
    "actual = np.asarray(parsedValData\n",
    "                    .map(lambda lp: lp.label)\n",
    "                    .collect())\n",
    "error = np.asarray(parsedValData\n",
    "                   .map(lambda lp: (lp.label, lp.label))\n",
    "                   .map(lambda (l, p): squaredError(l, p))\n",
    "                   .collect())\n",
    "clrs = cmap(np.asarray(norm(error)))[:,0:3]\n",
    "\n",
    "fig, ax = preparePlot(np.arange(0, 100, 20), np.arange(0, 100, 20))\n",
    "plt.scatter(actual, actual, s=14**2, c=clrs, edgecolors='#888888', alpha=0.75, linewidths=0.5)\n",
    "ax.set_xlabel('Predicted'), ax.set_ylabel('Actual')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = np.asarray(parsedValData\n",
    "                         .map(lambda lp: averageTrainYear)\n",
    "                         .collect())\n",
    "error = np.asarray(parsedValData\n",
    "                   .map(lambda lp: (lp.label, averageTrainYear))\n",
    "                   .map(lambda (l, p): squaredError(l, p))\n",
    "                   .collect())\n",
    "norm = Normalize()\n",
    "clrs = cmap(np.asarray(norm(error)))[:,0:3]\n",
    "\n",
    "fig, ax = preparePlot(np.arange(53.0, 55.0, 0.5), np.arange(0, 100, 20))\n",
    "ax.set_xlim(53, 55)\n",
    "plt.scatter(predictions, actual, s=14**2, c=clrs, edgecolors='#888888', alpha=0.75, linewidths=0.3)\n",
    "ax.set_xlabel('Predicted'), ax.set_ylabel('Actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Parte 3: Entrenamiento (vía descenso del gradiente) y evaluación de un modelo de regresión lineal **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (3a) sumando del gradiente **\n",
    "#### Veamos ahora si podemos hacerlo mejor usando regresión lineal entrenando un modelo por el método vía descenso del gradiente (omitimos el interceptor por ahora). Recordemos que el cálculo la siguiente iteración por el método del descenso del gradiente en una regresión lineal es: $$ \\scriptsize \\mathbf{w}_{i+1} = \\mathbf{w}_i - \\alpha_i \\sum_j (\\mathbf{w}_i^\\top\\mathbf{x}_j  - y_j) \\mathbf{x}_j \\,.$$ donde $ \\scriptsize i $ es el número de iteración del algoritmo de descenso de gradiente y $ \\scriptsize j $ identifica la observación.\n",
    "#### Primero implementa una función que calcula la suma en una iteración, esto es: $ \\scriptsize (\\mathbf{w}^\\top \\mathbf{x} - y) \\mathbf{x} \\, ,$ y prueba la función con dos ejemplos. Usa el método [dot](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.linalg.DenseVector.dot) de `DenseVector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import DenseVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Sustituye <RELLENA> con el código apropiado\n",
    "def gradientSummand(weights, lp):\n",
    "    \"\"\"Calcula el sumando del gradiente para un peso y un `LabeledPoint`.\n",
    "\n",
    "    Nota:\n",
    "        `DenseVector` se comporta de una manera similiar a `numpy.ndarray` y se pueden intercambiar dentro\n",
    "        de esta función. Por ejemplo ambos implementan el método `dot`.\n",
    "\n",
    "    Args:\n",
    "        weights (DenseVector): Un array de pesos del modelo (betas).\n",
    "        lp (LabeledPoint): El `LabeledPoint` para una única observación.\n",
    "\n",
    "    Returns:\n",
    "        DenseVector: Un array de valores  con la misma longitud que `weights`.  El sumando del gradiente.\n",
    "    \"\"\"\n",
    "    <RELLENA>\n",
    "\n",
    "exampleW = DenseVector([1, 1, 1])\n",
    "exampleLP = LabeledPoint(2.0, [3, 1, 4])\n",
    "# gradientSummand = (dot([1 1 1], [3 1 4]) - 2) * [3 1 4] = (8 - 2) * [3 1 4] = [18 6 24]\n",
    "summandOne = gradientSummand(exampleW, exampleLP)\n",
    "print summandOne\n",
    "\n",
    "exampleW = DenseVector([.24, 1.2, -1.4])\n",
    "exampleLP = LabeledPoint(3.0, [-1.4, 4.2, 2.1])\n",
    "summandTwo = gradientSummand(exampleW, exampleLP)\n",
    "print summandTwo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Sumando del gradiente (3a)\n",
    "Test.assertTrue(np.allclose(summandOne, [18., 6., 24.]), 'valor incorrecto para summandOne')\n",
    "Test.assertTrue(np.allclose(summandTwo, [1.7304,-5.1912,-2.5956]), 'valor incorrecto para summandTwo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (3b) Usa los pesos para hacer predicciones **\n",
    "#### A continuación implementa una función `getLabeledPredictions` que tome los pesos y una observación en formato  `LabeledPoint` y devuelva una tupla (label, prediction). Podremos predecir ahora calculando el dot product entre los pesos y las características de las observaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Sustituye <RELLENA> con el código apropiado\n",
    "def getLabeledPrediction(weights, observation):\n",
    "    \"\"\" Calcula predicciones y devuelve una tupla (label, prediction).\n",
    "\n",
    "    Nota:\n",
    "        Las etiquetas deberían permanecer sin cambios ya que usaremos esta información para calcular el error\n",
    "        de la predicción más tarde.\n",
    "\n",
    "    Args:\n",
    "        weights (np.ndarray): Un array con un peso por cada característica en `trainData`.\n",
    "        observation (LabeledPoint): un `LabeledPoint` que contiene la etiqueta correcta y las características\n",
    "        para el datapoint.\n",
    "    Returns:\n",
    "        tuple: una tupla (label, prediction).\n",
    "    \"\"\"\n",
    "    return <RELLENA>\n",
    "\n",
    "weights = np.array([1.0, 1.5])\n",
    "predictionExample = sc.parallelize([LabeledPoint(2, np.array([1.0, .5])),\n",
    "                                    LabeledPoint(1.5, np.array([.5, .5]))])\n",
    "labelsAndPredsExample = predictionExample.map(lambda lp: getLabeledPrediction(weights, lp))\n",
    "print labelsAndPredsExample.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Uso de pesos para hacer predicciones (3b)\n",
    "Test.assertEquals(labelsAndPredsExample.collect(), [(2.0, 1.75), (1.5, 1.25)],\n",
    "                  'incorrect definition for getLabeledPredictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (3c) Descenso de Gradiente **\n",
    "#### A continuación implementa una función para la regresión lineal y pruébala en un ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Sustituye <RELLENA> con el código apropiado\n",
    "def linregGradientDescent(trainData, numIters):\n",
    "    \"\"\" Calcula los pesos y el error para un modelo de regresión lineal entrenado con descenso de gradiente.\n",
    "\n",
    "    Note:\n",
    "       `DenseVector` se comporta de una manera similiar a `numpy.ndarray` y se pueden intercambiar dentro\n",
    "        de esta función. Por ejemplo ambos implementan el método `dot`.\n",
    "\n",
    "    Args:\n",
    "        trainData (RDD of LabeledPoint): Los datos etiquetados para su uso en el modelo de training.\n",
    "        numIters (int): Número de iteraciones que tiene que hacer el descenso de gradiente.\n",
    "\n",
    "    Returns:\n",
    "        (np.ndarray, np.ndarray): Una tupla de  (weights, training errors). Los pesos serán los pesos\n",
    "        finales (un peso por característica) del model, y los errores de training contendrán un error (RMSE)\n",
    "        para cada iteracion del algoritmo.\n",
    "    \"\"\"\n",
    "    # cuenta de los datos de training\n",
    "    n = trainData.count()\n",
    "    # número de características en los datos de training\n",
    "    d = len(trainData.take(1)[0].features)\n",
    "    w = np.zeros(d)\n",
    "    alpha = 1.0\n",
    "    # Calcularemos y almacenaremos el error de training después de cada iteración \n",
    "    errorTrain = np.zeros(numIters)\n",
    "    for i in range(numIters):\n",
    "        # Usa getLabeledPrediction de (3b) con trainData para obtener un RDD de tuplas (label, prediction)\n",
    "        # Los pesos son todos 0 para la primera iteración por lo que la predicción tendrá errores muy grandes\n",
    "        # al principio.\n",
    "        labelsAndPredsTrain = trainData.<RELLENA>\n",
    "        errorTrain[i] = calcRMSE(labelsAndPredsTrain)\n",
    "\n",
    "        # Calcula el `gradiente`. Utiliza la función `gradientSummand` de (3a).\n",
    "        # `gradient` debería ser un `DenseVector` de longitud `d`.\n",
    "        gradient = <RELLENA>\n",
    "\n",
    "        # actualiza los pesos\n",
    "        alpha_i = alpha / (n * np.sqrt(i+1))\n",
    "        w -= <RELLENA>\n",
    "    return w, errorTrain\n",
    "\n",
    "# Crea un dataset de juguete con n = 10, d = 3 y lo ejecuta 5 iteraciones\n",
    "# nota: El modelo resultante no es bueno pero el objetivo es verificar que \n",
    "# linregGradientDescent funciona\n",
    "exampleN = 10\n",
    "exampleD = 3\n",
    "exampleData = (sc\n",
    "               .parallelize(parsedTrainData.take(exampleN))\n",
    "               .map(lambda lp: LabeledPoint(lp.label, lp.features[0:exampleD])))\n",
    "print exampleData.take(2)\n",
    "exampleNumIters = 5\n",
    "exampleWeights, exampleErrorTrain = linregGradientDescent(exampleData, exampleNumIters)\n",
    "print exampleWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Descenso de gradiente (3c)\n",
    "expectedOutput = [48.88110449,  36.01144093, 30.25350092]\n",
    "Test.assertTrue(np.allclose(exampleWeights, expectedOutput), 'El valor de exampleWeights es incorrecto')\n",
    "expectedError = [79.72013547, 30.27835699,  9.27842641,  9.20967856,  9.19446483]\n",
    "Test.assertTrue(np.allclose(exampleErrorTrain, expectedError),\n",
    "                'El valor de exampleErrorTrain es incorrecto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (3d) Entrenar el model **\n",
    "#### Vamos a entrenar un modelo de regresión lineal con todo nuestro dataset de training y evaluar su precisión contra el set de validación. No usaremos el set de test aqui ya que si evaluamos el modelo contra el set de test podriamos distorsionar los resultados finales.\n",
    "#### Tenemos casi todo el trabajo hecho: Hemos calculado el número de características en la parte (1b), hemos creado los datasets de training y validación y calculado sus tamaños en la parte (1e) y hemos escrito una función que calcula el el RMSE  en la parte (2b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Sustituye <RELLENA> con el código apropiado\n",
    "numIters = 50\n",
    "weightsLR0, errorTrainLR0 = linregGradientDescent(<RELLENA>)\n",
    "\n",
    "labelsAndPreds = parsedValData.<RELLENA>\n",
    "rmseValLR0 = calcRMSE(labelsAndPreds)\n",
    "\n",
    "print 'Validación RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLR0 = {1:.3f}'.format(rmseValBase,\n",
    "                                                                       rmseValLR0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Entrenar el modelo (3d)\n",
    "expectedOutput = [22.64535883, 20.064699, -0.05341901, 8.2931319, 5.79155768, -4.51008084,\n",
    "                  15.23075467, 3.8465554, 9.91992022, 5.97465933, 11.36849033, 3.86452361]\n",
    "Test.assertTrue(np.allclose(weightsLR0, expectedOutput), 'valores incorrecto para weightsLR0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** Visualización 4: Error de training **\n",
    "#### Miraremos el logaritmo de error de entrenamiento (y) como una función de las iteraciones (x). El primer scatter plot visualiza esta función para las 50 primeras iteraciones. El segundo plot muestra el error en si mismo (sin logaritmo) viendo las últimas 44 iteraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm = Normalize()\n",
    "clrs = cmap(np.asarray(norm(np.log(errorTrainLR0))))[:,0:3]\n",
    "\n",
    "fig, ax = preparePlot(np.arange(0, 60, 10), np.arange(2, 6, 1))\n",
    "ax.set_ylim(2, 6)\n",
    "plt.scatter(range(0, numIters), np.log(errorTrainLR0), s=14**2, c=clrs, edgecolors='#888888', alpha=0.75)\n",
    "ax.set_xlabel('Iteration'), ax.set_ylabel(r'$\\log_e(errorTrainLR0)$')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm = Normalize()\n",
    "clrs = cmap(np.asarray(norm(errorTrainLR0[6:])))[:,0:3]\n",
    "\n",
    "fig, ax = preparePlot(np.arange(0, 60, 10), np.arange(17, 22, 1))\n",
    "ax.set_ylim(17.8, 21.2)\n",
    "plt.scatter(range(0, numIters-6), errorTrainLR0[6:], s=14**2, c=clrs, edgecolors='#888888', alpha=0.75)\n",
    "ax.set_xticklabels(map(str, range(6, 66, 10)))\n",
    "ax.set_xlabel('Iteration'), ax.set_ylabel(r'Training Error')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Parte 4: Entrenamiento usando MLib y ajuste de hiperparámetros via búsqueda en grid **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4a) `LinearRegressionWithSGD` **\n",
    "#### Ya lo estamos haciendo mejor que el modelo de baseline pero veamos si podemos hacerlo aún mejor añadiendo un interceptor, usando regularización y (basándonos en las visualizaciones previas) entrenando para más iteraciones. La función de MLib [LinearRegressionWithSGD](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LinearRegressionWithSGD) implementa el mismo algoritmo que hemos hecho en la parte (3b) de una manera un poco más eficiente y con funcionalidad adicional como la aproximación del gradiente estocástico, inclusión de un interceptor en el modelo y regularizaciones L1 y L2. Primero usaremos LinearRegressionWithSGD para entrenar un modelo con regularización L2 y con un interceptor. Este método devuelve un modelo [LinearRegressionModel](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LinearRegressionModel).  A continuación usaremos los pesos del modelo  [weights](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LinearRegressionModel.weights) e  [intercept](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LinearRegressionModel.intercept) para imprimir los parámetros del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LinearRegressionWithSGD\n",
    "# Valores a utilizar para entrenar el modelo de regresión lineal\n",
    "numIters = 500  # iteraciones\n",
    "alpha = 1.0  # paso (step)\n",
    "miniBatchFrac = 1.0  # miniBatchFraction\n",
    "reg = 1e-1  # parámetro de regularización (regParam) \n",
    "regType = 'l2'  # tipo de regularización (regType)\n",
    "useIntercept = True  # interceptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Sustituye <RELLENA> con el código apropiado\n",
    "firstModel = LinearRegressionWithSGD.<RELLENA>\n",
    "\n",
    "# weightsLR1 almacena los pesos del modelo ; interceptLR1 almacena los interceptores del modelo\n",
    "weightsLR1 = <RELLENA>\n",
    "interceptLR1 = <RELLENA>\n",
    "print weightsLR1, interceptLR1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST LinearRegressionWithSGD (4a)\n",
    "expectedIntercept = 13.3335907631\n",
    "expectedWeights = [16.682292427, 14.7439059559, -0.0935105608897, 6.22080088829, 4.01454261926, -3.30214858535,\n",
    "                   11.0403027232, 2.67190962854, 7.18925791279, 4.46093254586, 8.14950409475, 2.75135810882]\n",
    "Test.assertTrue(np.allclose(interceptLR1, expectedIntercept), 'valor incorrecto para interceptLR1')\n",
    "Test.assertTrue(np.allclose(weightsLR1, expectedWeights), 'valor incorrecto para weightsLR1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4b) Predicción**\n",
    "#### Ahora usaremos el método [LinearRegressionModel.predict()](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LinearRegressionModel.predict) para hacer predicciones sobre un punto de ejemplo. Pasa las  `features` de un `LabeledPoint` al método `predict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Sustituye <RELLENA> con el código apropiado\n",
    "samplePoint = parsedTrainData.take(1)[0]\n",
    "samplePrediction = <RELLENA>\n",
    "print samplePrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Predicción (4b)\n",
    "Test.assertTrue(np.allclose(samplePrediction, 56.8013380112),\n",
    "                'valor incorrecto para samplePrediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (4c) Evaluar RMSE **\n",
    "#### A continuación vamos a evaluar la precisión de este modelo con el set de validación. Usa el método `predict()` para cear un RDD de  `labelsAndPreds` y entonces utiliza la función  `calcRMSE()` de la parte (2b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Sustituye <RELLENA> con el código apropiado\n",
    "labelsAndPreds = <RELLENA>\n",
    "rmseValLR1 = <RELLENA>\n",
    "\n",
    "print ('Validación RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLR0 = {1:.3f}' +\n",
    "       '\\n\\tLR1 = {2:.3f}').format(rmseValBase, rmseValLR0, rmseValLR1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Evaluación RMSE (4c)\n",
    "Test.assertTrue(np.allclose(rmseValLR1, 19.691247), 'valor incorrecto para rmseValLR1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (4d) Búsqueda en Grid **\n",
    "#### Ya estamos superando como mínimo en 2 años la predicciones con respecto al baseline y con los datos del set de validación, veamos si podemos hacerlo todavía mejor. Vamos a realizar una búsqueda de un buen parámetro de regularización en un grid. vamos a probar `regParam` con los valores `1e-10`, `1e-5` y `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Sustituye <RELLENA> con el código apropiado\n",
    "bestRMSE = rmseValLR1\n",
    "bestRegParam = reg\n",
    "bestModel = firstModel\n",
    "\n",
    "numIters = 500\n",
    "alpha = 1.0\n",
    "miniBatchFrac = 1.0\n",
    "for reg in <RELLENA>:\n",
    "    model = LinearRegressionWithSGD.train(parsedTrainData, numIters, alpha,\n",
    "                                          miniBatchFrac, regParam=reg,\n",
    "                                          regType='l2', intercept=True)\n",
    "    labelsAndPreds = parsedValData.map(lambda lp: (lp.label, model.predict(lp.features)))\n",
    "    rmseValGrid = calcRMSE(labelsAndPreds)\n",
    "    print rmseValGrid\n",
    "\n",
    "    if rmseValGrid < bestRMSE:\n",
    "        bestRMSE = rmseValGrid\n",
    "        bestRegParam = reg\n",
    "        bestModel = model\n",
    "rmseValLRGrid = bestRMSE\n",
    "\n",
    "print ('Validación RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLR0 = {1:.3f}\\n\\tLR1 = {2:.3f}\\n' +\n",
    "       '\\tLRGrid = {3:.3f}').format(rmseValBase, rmseValLR0, rmseValLR1, rmseValLRGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Búsqueda en grid (4d)\n",
    "Test.assertTrue(np.allclose(17.017170, rmseValLRGrid), 'valor incorrecto para rmseValLRGrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** Visualización 5: Mejor modelo de predicción**\n",
    "#### Vamos a crear una visualización similar a la 'Visualización 3: Predichos vs. reales' de la parte 2 utilizando las prediciones del mejor modelo de la parte (4d) sobre el dataset de validación. En concreto, crearemos un scatter plot con códigos de color para visualizar tuplas que almacenan i) el valor predicho para este modelo y ii) la etiqueta verdadera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = np.asarray(parsedValData\n",
    "                         .map(lambda lp: bestModel.predict(lp.features))\n",
    "                         .collect())\n",
    "actual = np.asarray(parsedValData\n",
    "                    .map(lambda lp: lp.label)\n",
    "                    .collect())\n",
    "error = np.asarray(parsedValData\n",
    "                   .map(lambda lp: (lp.label, bestModel.predict(lp.features)))\n",
    "                   .map(lambda (l, p): squaredError(l, p))\n",
    "                   .collect())\n",
    "\n",
    "norm = Normalize()\n",
    "clrs = cmap(np.asarray(norm(error)))[:,0:3]\n",
    "\n",
    "fig, ax = preparePlot(np.arange(0, 120, 20), np.arange(0, 120, 20))\n",
    "ax.set_xlim(15, 82), ax.set_ylim(-5, 105)\n",
    "plt.scatter(predictions, actual, s=14**2, c=clrs, edgecolors='#888888', alpha=0.75, linewidths=.5)\n",
    "ax.set_xlabel('Predicted'), ax.set_ylabel(r'Actual')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (4e) Cambiando alpha y el número de iteraciones **\n",
    "#### En la búsqueda en grid previa establecimos  `alpha = 1` para todos los experimentos. Veamos ahora que sucede si variamos  `alpha`.  En concreto vamos a probar  `1e-5` y `10` como valores para `alpha` entrenando modelos con 500 iteracciones (como antes) pero también para 5 iteracciones. Evaluaremos todos los modelos con el dataset de validación. Si ponemos `alpha` muy pequeño el descenso del gradiente necesitará un gran número de pasos para converger a la solución y si utilizamos un `alpha` muy grande puede ocasionar problemas numéricos, como verás para `alpha = 10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Sustituye <RELLENA> con el código apropiado\n",
    "reg = bestRegParam\n",
    "modelRMSEs = []\n",
    "\n",
    "for alpha in <RELLENA>:\n",
    "    for numIters in <RELLENA>:\n",
    "        model = LinearRegressionWithSGD.train(parsedTrainData, numIters, alpha,\n",
    "                                              miniBatchFrac, regParam=reg,\n",
    "                                              regType='l2', intercept=True)\n",
    "        labelsAndPreds = parsedValData.map(lambda lp: (lp.label, model.predict(lp.features)))\n",
    "        rmseVal = calcRMSE(labelsAndPreds)\n",
    "        print 'alpha = {0:.0e}, numIters = {1}, RMSE = {2:.3f}'.format(alpha, numIters, rmseVal)\n",
    "        modelRMSEs.append(rmseVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Variar alpha y el número de iteraciones(4e)\n",
    "expectedResults = sorted([56.969705, 56.892949, 355124752.221221])\n",
    "Test.assertTrue(np.allclose(sorted(modelRMSEs)[:3], expectedResults), 'valor incorrecto para modelRMSEs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Visualización 6: Mapa de calor de hiperparámetros **\n",
    "#### A continuación realizaremos una visualización de búsqueda de hiperparámetros usando un conjunto grande de hiperparámetros precalculados. En concreto vamos a crear un mapa de calor donde los colores más brillantes se correponda con los valores más bajos de RMSE. El primer plot tiene un gran área de colores brillantes, para poder diferenciar dentro de esta región generamos un segundo plot con los hiperparámetros encontrados en ese área."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Saved parameters and results, to save the time required to run 36 models\n",
    "numItersParams = [10, 50, 100, 250, 500, 1000]\n",
    "regParams = [1e-8, 1e-6, 1e-4, 1e-2, 1e-1, 1]\n",
    "rmseVal = np.array([[  20.36769649,   20.36770128,   20.36818057,   20.41795354,  21.09778437,  301.54258421],\n",
    "                    [  19.04948826,   19.0495    ,   19.05067418,   19.16517726,  19.97967727,   23.80077467],\n",
    "                    [  18.40149024,   18.40150998,   18.40348326,   18.59457491,  19.82155716,   23.80077467],\n",
    "                    [  17.5609346 ,   17.56096749,   17.56425511,   17.88442127,  19.71577117,   23.80077467],\n",
    "                    [  17.0171705 ,   17.01721288,   17.02145207,   17.44510574,  19.69124734,   23.80077467],\n",
    "                    [  16.58074813,   16.58079874,   16.58586512,   17.11466904,  19.6860931 ,   23.80077467]])\n",
    "\n",
    "numRows, numCols = len(numItersParams), len(regParams)\n",
    "rmseVal = np.array(rmseVal)\n",
    "rmseVal.shape = (numRows, numCols)\n",
    "\n",
    "fig, ax = preparePlot(np.arange(0, numCols, 1), np.arange(0, numRows, 1), figsize=(8, 7), hideLabels=True,\n",
    "                      gridWidth=0.)\n",
    "ax.set_xticklabels(regParams), ax.set_yticklabels(numItersParams)\n",
    "ax.set_xlabel('Regularization Parameter'), ax.set_ylabel('Number of Iterations')\n",
    "\n",
    "colors = LinearSegmentedColormap.from_list('blue', ['#0022ff', '#000055'], gamma=.2)\n",
    "image = plt.imshow(rmseVal,interpolation='nearest', aspect='auto',\n",
    "                    cmap = colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Zoom a abajo a la izquierda\n",
    "numItersParamsZoom, regParamsZoom = numItersParams[-3:], regParams[:4]\n",
    "rmseValZoom = rmseVal[-3:, :4]\n",
    "\n",
    "numRows, numCols = len(numItersParamsZoom), len(regParamsZoom)\n",
    "\n",
    "fig, ax = preparePlot(np.arange(0, numCols, 1), np.arange(0, numRows, 1), figsize=(8, 7), hideLabels=True,\n",
    "                      gridWidth=0.)\n",
    "ax.set_xticklabels(regParamsZoom), ax.set_yticklabels(numItersParamsZoom)\n",
    "ax.set_xlabel('Regularization Parameter'), ax.set_ylabel('Number of Iterations')\n",
    "\n",
    "colors = LinearSegmentedColormap.from_list('blue', ['#0022ff', '#000055'], gamma=.2)\n",
    "image = plt.imshow(rmseValZoom,interpolation='nearest', aspect='auto',\n",
    "                    cmap = colors)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Parte 5: Añadir interaciones entre características **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (5a) Añadir interacciones de dos vías **\n",
    "#### Hasta ahora hemos utilizado las características tal y como nos venían dadas. Ahora vamos a añadir características que capturen interacciones de dos vías entre las características existentes (ver slides). Escribe una función `twoWayInteractions` que tome un `LabeledPoint` y genere un nuevo `LabeledPoint` que contenga las antiguas características y la interaciones de dos vías entre ellas. Por ejemplo un dataset con tres características tendría ahora nueve interacciones de dos vías  ( $ \\scriptsize 3^2 $ ).\n",
    "#### Puedes utilizar [itertools.product](https://docs.python.org/2/library/itertools.html#itertools.product) para genera tuplas por cada interacción de dos vías. Recuerda que puedes combinar dos objetos `DenseVector` o `ndarray` utilizando [np.hstack](http://docs.scipy.org/doc/numpy/reference/generated/numpy.hstack.html#numpy.hstack)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Sustituye <RELLENA> con el código apropiado\n",
    "import itertools\n",
    "\n",
    "def twoWayInteractions(lp):\n",
    "    \"\"\"Crea un nuevo `LabeledPoint` que incluye interaciones de dos vias.\n",
    "\n",
    "    Note:\n",
    "        Para las características [x, y] las interaciones de dos vías serían [x^2, x*y, y*x, y^2] \n",
    "        y las añadiríamos a la lista [x, y] de características original.\n",
    "\n",
    "    Args:\n",
    "        lp (LabeledPoint): La etiquete y las características para esta observación\n",
    "        \n",
    "    Returns:\n",
    "        LabeledPoint: La nueva `LabeledPoint` debería tener la misma etiqueta que `lp`. Sus características\n",
    "        deberían incluir las caracteríticas de `lp` seguidas de las características de dos vías.\n",
    "    \"\"\"\n",
    "    <RELLENA>\n",
    "\n",
    "print twoWayInteractions(LabeledPoint(0.0, [2, 3]))\n",
    "\n",
    "# Transforma los datasets de entrenamiento validación y test para incluir las interaciones de dos vías.\n",
    "trainDataInteract = <RELLENA>\n",
    "valDataInteract = <RELLENA>\n",
    "testDataInteract = <RELLENA>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST añade interacciones de dos vías (5a)\n",
    "twoWayExample = twoWayInteractions(LabeledPoint(0.0, [2, 3]))\n",
    "Test.assertTrue(np.allclose(sorted(twoWayExample.features),\n",
    "                            sorted([2.0, 3.0, 4.0, 6.0, 6.0, 9.0])),\n",
    "                'Características incorrectas generadas por twoWayInteractions 1')\n",
    "twoWayPoint = twoWayInteractions(LabeledPoint(1.0, [1, 2, 3]))\n",
    "Test.assertTrue(np.allclose(sorted(twoWayPoint.features),\n",
    "                            sorted([1.0,2.0,3.0,1.0,2.0,3.0,2.0,4.0,6.0,3.0,6.0,9.0])),\n",
    "                'Características incorrectas generadas por twoWayInteractions 2')\n",
    "Test.assertEquals(twoWayPoint.label, 1.0, 'Etiqueta incorrecta generada por twoWayInteractions')\n",
    "Test.assertTrue(np.allclose(sum(trainDataInteract.take(1)[0].features), 40.821870576035529),\n",
    "                'características incorrectas en trainDataInteract')\n",
    "Test.assertTrue(np.allclose(sum(valDataInteract.take(1)[0].features), 45.457719932695696),\n",
    "                'características incorrectas en valDataInteract')\n",
    "Test.assertTrue(np.allclose(sum(testDataInteract.take(1)[0].features), 35.109111632783168),\n",
    "                'características incorrectas en testDataInteract')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (5b) Construir el modelo de interacción **\n",
    "#### Ahora vamos a construir el nuevo modelo. Para implementarlo con las nuevas características tenemos que cambiar algunos nombres de variables. Recuerda que deberíamos construir nuestro modelo con el dataset de training y evaluarlo con el de validación.\n",
    "\n",
    "####  Debes de volver a ejecutar la búsqueda de hiperparámetros después de cambiar las características ya que los mejores hiperparámetros del modelo anterior no tienen porque ser necesariamente los mismos para el nuevo modelo. Para este ejercicio ya se han establecido los hiperparámetros a valores razonables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Sustituye <RELLENA> con el código apropiado\n",
    "numIters = 500\n",
    "alpha = 1.0\n",
    "miniBatchFrac = 1.0\n",
    "reg = 1e-10\n",
    "\n",
    "modelInteract = LinearRegressionWithSGD.train(<RELLENA>, numIters, alpha,\n",
    "                                              miniBatchFrac, regParam=reg,\n",
    "                                              regType='l2', intercept=True)\n",
    "labelsAndPredsInteract = <RELLENA>.map(lambda lp: (lp.label, <RELLENA>.predict(lp.features)))\n",
    "rmseValInteract = calcRMSE(labelsAndPredsInteract)\n",
    "\n",
    "print ('Validación RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLR0 = {1:.3f}\\n\\tLR1 = {2:.3f}\\n\\tLRGrid = ' +\n",
    "       '{3:.3f}\\n\\tLRInteract = {4:.3f}').format(rmseValBase, rmseValLR0, rmseValLR1,\n",
    "                                                 rmseValLRGrid, rmseValInteract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Construir el modelo de interacción (5b)\n",
    "Test.assertTrue(np.allclose(rmseValInteract, 15.6894664683), 'valor incorrecto para rmseValInteract')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (5c) Evaluar el modelo de interacción en los datos de test**\n",
    "#### El último paso para evaluar el nuevo modelo es probarlo en el dataset de test. NO hemos utilizado aún el set de test para evaluar ninguno de los modelos. Así nuestra evaluacion nos proporcionará una estimación no sesgada de como se comportará el modelo con nuevos datos. Si hubiésemos cambiado nuestro modelo basándonos en como se hubiese comportado con el set de test nuestra estimacion de RMSE podría haber sido optimista.\n",
    "\n",
    "#### También vamos a imprimir el RMSE para tanto para el modelo base como para el nuevo modelo, con esta información podemos ver como mejora el modelo con respecto al modelo base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Sustituye <RELLENA> con el código apropiado\n",
    "labelsAndPredsTest = <RELLENA>\n",
    "rmseTestInteract = <RELLENA>\n",
    "\n",
    "print ('Test RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLRInteract = {1:.3f}'\n",
    "       .format(rmseTestBase, rmseTestInteract))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Evalua el modelo de interacción sobre los datos de test(5c)\n",
    "Test.assertTrue(np.allclose(rmseTestInteract, 16.3272040537),\n",
    "                'valores incorrecto para rmseTestInteract')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
