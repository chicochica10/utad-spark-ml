{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ML Logo](https://raw.githubusercontent.com/chicochica10/utad-spark-ml/master/images/utad-spark-ml.1x_Banner_300.png)\n",
    "# **Lab de predicción de tasas de clics**\n",
    "#### Este lab cubre los pasos para crear un pipeline de predición de tasas de clics. Trabajarás con el dataset de [Criteo Labs](http://labs.criteo.com/) que se usó en la  [competición Kaggle](https://www.kaggle.com/c/criteo-display-ad-challenge).\n",
    "#### ** Este lab cubre: **\n",
    "+  ####*Parte 1:* Caracterización categórica de datos utilizando one-hot-encoding (OHE)\n",
    "+  ####*Parte 2:* Construcción del diccionario OHE\n",
    "+  ####*Part 3:* Parseo de datos CTR y generación de características OHE\n",
    " + #### *Visualización 1:* Frecuencia de características \n",
    "+  ####*Parte 4:* predicción CTR y evaluación logloss\n",
    " + #### *Visualización 2:* curva ROC\n",
    " \n",
    "#### como referencia tienes los métodods de spark más relevantes en [Spark's Python API](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD) y los métodos de NumPy en [NumPy Reference](http://docs.scipy.org/doc/numpy/reference/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte 1: Caracterización categórica de datos utilizando one-hot-encoding (OHE)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (1a) One-hot-encoding **\n",
    "#### vamos a desarrollar código para convertir características categóricas a numéricas, trabajaremos con un dataset de ejemplo no etiquetado con 3 data points que representan a un animal. La primera característica indica el tipo del animal (bear, cat, mouse), la segunda característica indica el color (black, tabby) y la tercera (opcional) describe lo que el animal come (mouse, salmon).\n",
    "\n",
    "#### En el esquema OHE queremos representar cada tupla de `(featureID, category)` via su  propia representacion binaria. Podemos hacer esto en Python creando un diccionario que mapee cada tupla a un entero distinto donde cada entero corresponda a una característica binaria. para empezar se introducen manualmente la entradas en el diccionario OHE asociado al dataset de ejemplo mapeando las tuplas a enterors consecutivos empezando desde cero y ordenando las tuplas primero por featureID y después por categoria.\n",
    "\n",
    "#### Después en el lab usaremos los diccionarios OHE para transformar data points en una lista más compacta de características que se pueden utilizar en algoritmos de machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Datos para la entrada manual OHE\n",
    "# Nota: el primer data point no incluye ningún valor para la tercera característica opcional\n",
    "sampleOne = [(0, 'mouse'), (1, 'black')]\n",
    "sampleTwo = [(0, 'cat'), (1, 'tabby'), (2, 'mouse')]\n",
    "sampleThree =  [(0, 'bear'), (1, 'black'), (2, 'salmon')]\n",
    "sampleDataRDD = sc.parallelize([sampleOne, sampleTwo, sampleThree])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: Reemplaza <RELLENA> con el código apropiado\n",
    "sampleOHEDictManual = {}\n",
    "sampleOHEDictManual[(0,'bear')] = <RELLENA>\n",
    "sampleOHEDictManual[(0,'cat')] = <RELLENA>\n",
    "sampleOHEDictManual[(0,'mouse')] = <RELLENA>\n",
    "sampleOHEDictManual<RELLENA>\n",
    "sampleOHEDictManual<RELLENA>\n",
    "sampleOHEDictManual<RELLENA>\n",
    "sampleOHEDictManual<RELLENA>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST One-hot-encoding (1a)\n",
    "from test_helper import Test\n",
    "\n",
    "Test.assertEqualsHashed(sampleOHEDictManual[(0,'bear')],\n",
    "                        'b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
    "                        \"valor incorrecto para sampleOHEDictManual[(0,'bear')]\")\n",
    "Test.assertEqualsHashed(sampleOHEDictManual[(0,'cat')],\n",
    "                        '356a192b7913b04c54574d18c28d46e6395428ab',\n",
    "                        \"valor incorrecto para sampleOHEDictManual[(0,'cat')]\")\n",
    "Test.assertEqualsHashed(sampleOHEDictManual[(0,'mouse')],\n",
    "                        'da4b9237bacccdf19c0760cab7aec4a8359010b0',\n",
    "                        \"valor incorrecto para sampleOHEDictManual[(0,'mouse')]\")\n",
    "Test.assertEqualsHashed(sampleOHEDictManual[(1,'black')],\n",
    "                        '77de68daecd823babbb58edb1c8e14d7106e83bb',\n",
    "                        \"valor incorrecto para sampleOHEDictManual[(1,'black')]\")\n",
    "Test.assertEqualsHashed(sampleOHEDictManual[(1,'tabby')],\n",
    "                        '1b6453892473a467d07372d45eb05abc2031647a',\n",
    "                        \"valor incorrecto para sampleOHEDictManual[(1,'tabby')]\")\n",
    "Test.assertEqualsHashed(sampleOHEDictManual[(2,'mouse')],\n",
    "                        'ac3478d69a3c81fa62e60f5c3696165a4e5e6ac4',\n",
    "                        \"valor incorrecto para sampleOHEDictManual[(2,'mouse')]\")\n",
    "Test.assertEqualsHashed(sampleOHEDictManual[(2,'salmon')],\n",
    "                        'c1dfd96eea8cc2b62785275bca38ac261256e278',\n",
    "                        \"valor incorrecto para sampleOHEDictManual[(2,'salmon')]\")\n",
    "Test.assertEquals(len(sampleOHEDictManual.keys()), 7,\n",
    "                  'numero de claves incorrecto sampleOHEDictManual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (1b) Vectores Sparse **\n",
    "#### Los data points se pueden representar con un pequeño número de características OHE no-cero relativas al número total de características que hay en el dataset. Aprovechando esta escasez y  usando represetación de vectores sparse en los datos OHE podemos reducir los costes de almacenamiento y computacionales. Abajo hay unos pocos ejemplos de vectores representados como arrays densos de numpy. Utiliza   [SparseVector](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.linalg.SparseVector) para representarlos de forma sparse y verifica que tanto las representaciones dense como sparse devuelven los mismos resultados cuando se calcula el [dot products](http://en.wikipedia.org/wiki/Dot_product) (más adelante utilizaremos Mlib para entrenar clasificadores vía el descenso del gradiente y MLib necesitará estos vectores computar el dot product entre SparseVector y vectores densos de parámetros).\n",
    "\n",
    "#### Utiliza  `SparseVector(size, *args)`  para crear un nuevo vector sparse donde el tamaño es la longitud del vector y los argumentos puedan ser un diccionario , una lista de  pares (index, value) o dos arrays separados de índices y valores ordenados por índices. Necesitarás crear una representación de un vector sparse por cada vector dendos `aDense` y `bDense`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark.mllib.linalg import SparseVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: Reemplaza <RELLENA> con el código apropiado\n",
    "aDense = np.array([0., 3., 0., 4.])\n",
    "aSparse = <RELLENA>\n",
    "\n",
    "bDense = np.array([0., 0., 0., 1.])\n",
    "bSparse = <RELLENA>\n",
    "\n",
    "w = np.array([0.4, 3.1, -1.4, -.5])\n",
    "print aDense.dot(w)\n",
    "print aSparse.dot(w)\n",
    "print bDense.dot(w)\n",
    "print bSparse.dot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Sparse Vectors (1b)\n",
    "Test.assertTrue(isinstance(aSparse, SparseVector), 'aSparse tiene que ser una instancia de SparseVector')\n",
    "Test.assertTrue(isinstance(bSparse, SparseVector), 'aSparse tiene que ser una instancia de SparseVector')\n",
    "Test.assertTrue(aDense.dot(w) == aSparse.dot(w),\n",
    "                'dot product de aDense y w debería ser igual al dot product de aSparse y w')\n",
    "Test.assertTrue(bDense.dot(w) == bSparse.dot(w),\n",
    "                'dot product de bDense y w debería ser igual al dot product de bSparse y w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1c) características OHE  como vectores sparse **\n",
    "#### Ahora veamos como se pueden representar las características OHE para los puntos en nuestro dataset de ejemplo.  Usando el mapeo definido por el diccionario de OHE de la parte (1a), define manualmente las característica de OHE para los tres data points de ejemplo usando el formato SparseVector. Cualquier característica que ocurra en un punto debería tener el valor 1.0. Por ejemplo, el  `DenseVector` para un punto con características 2 y 4 debería de ser  `[0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# características de ejemplo\n",
    "# sampleOne = [(0, 'mouse'), (1, 'black')]\n",
    "# sampleTwo = [(0, 'cat'), (1, 'tabby'), (2, 'mouse')]\n",
    "# sampleThree =  [(0, 'bear'), (1, 'black'), (2, 'salmon')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: Reemplaza <RELLENA> con el código apropiado\n",
    "sampleOneOHEFeatManual = <RELLENA>\n",
    "sampleTwoOHEFeatManual = <RELLENA>\n",
    "sampleThreeOHEFeatManual = <RELLENA>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST de características OHE como vectores sparse (1c)\n",
    "Test.assertTrue(isinstance(sampleOneOHEFeatManual, SparseVector),\n",
    "                'sampleOneOHEFeatManual debe ser SparseVector')\n",
    "Test.assertTrue(isinstance(sampleTwoOHEFeatManual, SparseVector),\n",
    "                'sampleTwoOHEFeatManual debe ser SparseVector')\n",
    "Test.assertTrue(isinstance(sampleThreeOHEFeatManual, SparseVector),\n",
    "                'sampleThreeOHEFeatManual debe ser SparseVector')\n",
    "Test.assertEqualsHashed(sampleOneOHEFeatManual,\n",
    "                        'ecc00223d141b7bd0913d52377cee2cf5783abd6',\n",
    "                        'valor incorrecto para sampleOneOHEFeatManual')\n",
    "Test.assertEqualsHashed(sampleTwoOHEFeatManual,\n",
    "                        '26b023f4109e3b8ab32241938e2e9b9e9d62720a',\n",
    "                        'valor incorrecto para sampleTwoOHEFeatManual')\n",
    "Test.assertEqualsHashed(sampleThreeOHEFeatManual,\n",
    "                        'c04134fd603ae115395b29dcabe9d0c66fbdc8a7',\n",
    "                        'valor incorrecto para sampleThreeOHEFeatManual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1d) Definir una función OHE **\n",
    "#### A continuación usaremos el diccionario de la parte (1a) para generar programáticamente las características OHE de los datos categóricos originales. Primero escribiremos una función llamada  `oneHotEncoding` que cree un vector de características OHe en el formato  `SparseVector`. Después utilizaremos esta función para crear las características OHE para primer datapoint de ejemplo y verificaremos que el resultado es igual que el de la parte (1c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: Reemplaza <RELLENA> con el código apropiado\n",
    "def oneHotEncoding(rawFeats, OHEDict, numOHEFeats):\n",
    "    \"\"\" produce un one-hot-encoding a partir de una lista de características y un diccionario OHE\n",
    "\n",
    "    Nota:\n",
    "        asegurate que los indices usados para crear el SparseVector estan ordenados.\n",
    "\n",
    "    Args:\n",
    "        rawFeats (list of (int, str)): La características correspondientes a una única observación. Cada\n",
    "            característica consiste en una tupla de featureID y el valor de la característica (por ejemplo: sampleOne)\n",
    "        \n",
    "        OHEDict (dict): Un mapeo de (featureID, valor) a un unico entero\n",
    "        \n",
    "        numOHEFeats (int): el número total de características únicas OHE (combinaciones de featureID y valor) \n",
    "        \n",
    "\n",
    "    Returns:\n",
    "        SparseVector: un SparseVector de longitud numOHEFeats con indices igual a los identificadores unicos para las\n",
    "        combinaciones (featureID, valor) que ocurren en la observacion y con valores igual a 1.0\n",
    "    \"\"\"\n",
    "    <RELLENA>\n",
    "\n",
    "# calcular el numero de caracteristicas en sampleOHEDictManual\n",
    "numSampleOHEFeats = <RELLENA>\n",
    "\n",
    "# correr oneHotEnoding en sampleOne\n",
    "sampleOneOHEFeat = <RELLENA>\n",
    "\n",
    "print sampleOneOHEFeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Define an OHE Function (1d)\n",
    "Test.assertTrue(sampleOneOHEFeat == sampleOneOHEFeatManual,\n",
    "                'sampleOneOHEFeat deberia ser igual sampleOneOHEFeatManual')\n",
    "Test.assertEquals(sampleOneOHEFeat, SparseVector(7, [2,3], [1.0,1.0]),\n",
    "                  'valor incorrecto para sampleOneOHEFeat')\n",
    "Test.assertEquals(oneHotEncoding([(1, 'black'), (0, 'mouse')], sampleOHEDictManual,\n",
    "                                 numSampleOHEFeats), SparseVector(7, [2,3], [1.0,1.0]),\n",
    "                  'definicion incorrecta para oneHotEncoding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1e) aplicar OHE al dataset **\n",
    "#### Finalmente utilizar la función de la parte (1d) para crear características OHE  para 3 datapoints del dataset de ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: Reemplaza <RELLENA> con el código apropiado\n",
    "sampleOHEData = sampleDataRDD.<RELLENA>\n",
    "print sampleOHEData.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST aplicar OHE  a un dataset (1e)\n",
    "sampleOHEDataValues = sampleOHEData.collect()\n",
    "Test.assertTrue(len(sampleOHEDataValues) == 3, 'sampleOHEData deberia tener 3 elemenos')\n",
    "Test.assertEquals(sampleOHEDataValues[0], SparseVector(7, {2: 1.0, 3: 1.0}),\n",
    "                  'OHE incorrecto para el primer ejemplo')\n",
    "Test.assertEquals(sampleOHEDataValues[1], SparseVector(7, {1: 1.0, 4: 1.0, 5: 1.0}),\n",
    "                  'OHE incorrecto para el segundo ejemplo')\n",
    "Test.assertEquals(sampleOHEDataValues[2], SparseVector(7, {0: 1.0, 3: 1.0, 6: 1.0}),\n",
    "                  'OHE incorrecto para el tercer ejemplo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Parte 2: Construcción del diccionario OHE **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2a)  RDD de pares `(featureID, category)` **\n",
    "#### Para empezar crea un RDD de tuplas distintas `(featureID, category)`. En nuestro dataset de ejemplo los 7 items en RDD resultante son `(0, 'bear')`, `(0, 'cat')`, `(0, 'mouse')`, `(1, 'black')`, `(1, 'tabby')`, `(2, 'mouse')`, `(2, 'salmon')`.  `'black'` aparece dos veces en el dataset pero solamente uno de los items contribuye al RDD: `(1, 'black')`, mientras `'mouse'` aparece dos veces y contribuye a dos items: `(0, 'mouse')` and `(2, 'mouse')`.  Usa [flatMap](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.flatMap) y [distinct](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.distinct)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: Reemplaza <RELLENA> con el código apropiado\n",
    "sampleDistinctFeats = (sampleDataRDD\n",
    "                       <RELLENA>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST pares de RDD de (featureID, category) (2a)\n",
    "Test.assertEquals(sorted(sampleDistinctFeats.collect()),\n",
    "                  [(0, 'bear'), (0, 'cat'), (0, 'mouse'), (1, 'black'),\n",
    "                   (1, 'tabby'), (2, 'mouse'), (2, 'salmon')],\n",
    "                  'valor incorrecto para sampleDistinctFeats')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (2b) Diccionario OHE Dictionary para distintas características  **\n",
    "#### A continuación, crea un `RDD` de tuplas clave-valor donde cada  tupla `(featureID, category)` en `sampleDistinctFeats` es una clave y los valores son entereos distintos desde 0 a (número de claves -1). Convierte este  `RDD` en un diccionario que pueda ser usado en la acción  `collectAsMap`. Nota que no hay un único mapeo de claves a valores todo lo que se requieres es que cada `(featureID, category)` clave se mapee a un entero único entre 0 y el número de claves. En este ejercicio, cualquier mapeo válido es aceptable. Utiliza [zipWithIndex](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.zipWithIndex) seguido de  [collectAsMap](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.collectAsMap).\n",
    "#### En nuestro dataset de ejemplo una lista de tuplas clave-valor válida es: `[((0, 'bear'), 0), ((2, 'salmon'), 1), ((1, 'tabby'), 2), ((2, 'mouse'), 3), ((0, 'mouse'), 4), ((0, 'cat'), 5), ((1, 'black'), 6)]`. El diccionario definido en la parte (1a) muestra otro mapeo válido entre claves y enteros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: Reemplaza <RELLENA> con el código apropiado\n",
    "sampleOHEDict = (sampleDistinctFeats\n",
    "                           <RELLENA>)\n",
    "print sampleOHEDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Diccionario OHE para distintas características (2b)\n",
    "Test.assertEquals(sorted(sampleOHEDict.keys()),\n",
    "                  [(0, 'bear'), (0, 'cat'), (0, 'mouse'), (1, 'black'),\n",
    "                   (1, 'tabby'), (2, 'mouse'), (2, 'salmon')],\n",
    "                  'sampleOHEDict has unexpected keys')\n",
    "Test.assertEquals(sorted(sampleOHEDict.values()), range(7), 'sampleOHEDict tiene valores no esperados')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2c) Creación automática de un diccionario OHE **\n",
    "#### Usa el código de las partes (2a) y (2b) para escribir una función que tome un dataset de entrada y como salida un diccionario OHE. Usa esta función para acrear un diccionario OHE con el dataset de ejemplo y verifica que es igual que el diccionario de la parte (2b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: Reemplaza <RELLENA> con el código apropiado\n",
    "def createOneHotDict(inputData):\n",
    "    \"\"\" Crea un diccionario one-hot-encoder basado en inputData.\n",
    "\n",
    "    Args:\n",
    "        inputData (RDD de listas de (int, str)): Un RDD de observaciones donde cada observación \n",
    "        es una lista de tuplas (featureID, value).\n",
    "\n",
    "    Returns:\n",
    "        dict: Un diccionario donde las claves son tuplas (featureID, value) y mapea a valores que son enteros únicos\n",
    "    \"\"\"\n",
    "    <RELLENA>\n",
    "\n",
    "sampleOHEDictAuto = <RELLENA>\n",
    "print sampleOHEDictAuto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Creación automática de un diccionario OHE (2c)\n",
    "Test.assertEquals(sorted(sampleOHEDictAuto.keys()),\n",
    "                  [(0, 'bear'), (0, 'cat'), (0, 'mouse'), (1, 'black'),\n",
    "                   (1, 'tabby'), (2, 'mouse'), (2, 'salmon')],\n",
    "                  'sampleOHEDictAuto has unexpected keys')\n",
    "Test.assertEquals(sorted(sampleOHEDictAuto.values()), range(7),\n",
    "                  'sampleOHEDictAuto has unexpected values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte 3: Parseo de datos CTR y generación de características OHE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3a) Carga y split de datos **\n",
    "#### Ahora estamos listo para trabajar con datos CTR reales y nuestra primera tarea será dividirlos en sets de training, validación y test usando[randomSplit method](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.randomSplit) con los pesos y semillas especificados para crear RDDs que almacenen cada uno de estos dataset y entonces hacer [cache](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.cache) en cada uno de los RDDs ya que se van a acceder multiples veces.\n",
    "\n",
    "#### carga el fichero cad.txt desde jupyter home y déjalo en el directorio data/utad-spark-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "baseDir = os.path.join('data')\n",
    "inputPath = os.path.join('utad-spark-ml', 'cad.txt')\n",
    "fileName = os.path.join(baseDir, inputPath)\n",
    "\n",
    "if os.path.isfile(fileName):\n",
    "    rawData = (sc\n",
    "               .textFile(fileName, 2)\n",
    "               .map(lambda x: x.replace('\\t', ',')))\n",
    "    print rawData.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: Reemplaza <RELLENA> con el código apropiado\n",
    "weights = [.8, .1, .1]\n",
    "seed = 42\n",
    "#  randomSplit con pesos y semilla\n",
    "rawTrainData, rawValidationData, rawTestData = rawData.<RELLENA>\n",
    "# Cache the data\n",
    "<RELLENA>\n",
    "\n",
    "nTrain = <RELLENA>\n",
    "nVal = <RELLENA>\n",
    "nTest = <RELLENA>\n",
    "print nTrain, nVal, nTest, nTrain + nVal + nTest\n",
    "print rawData.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Loading and splitting the data (3a)\n",
    "Test.assertTrue(all([rawTrainData.is_cached, rawValidationData.is_cached, rawTestData.is_cached]),\n",
    "                'debes cachear los datos')\n",
    "Test.assertEquals(nTrain, 1596, 'valor incorrecto para nTrain')\n",
    "Test.assertEquals(nVal, 210, 'valor incorrecto para nVal')\n",
    "Test.assertEquals(nTest, 193, 'valor incorrecto para nTest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (3b) Extraer características **\n",
    "#### parsearemos el dataset en bruto de training para crear un RDD que sirva para crear un directorio OHE. Nota que el comando `take()` en la parte (3a) que es un data point es un string que contiene varios campos separados por un delimitador. De momento vamos a ignorar el primer campo (que es una etiqueta 0-1) y parsear el resto de los campos. Completa la función `parsePoint`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: Reemplaza <RELLENA> con el código apropiado\n",
    "def parsePoint(point):\n",
    "    \"\"\"convierte una cadena separada por comas en una liasta de tuplas (featureID, value).\n",
    "\n",
    "    Note:\n",
    "        featureIDs deben empezar en 0 e incrementarse hasta el número de características  - 1.\n",
    "\n",
    "    Args:\n",
    "        point (str): una string separada por coma en la que el primer valor es la etiqueta y el resto las características\n",
    "\n",
    "    Returns:\n",
    "        list: Una lista de tuplas (featureID, value) .\n",
    "    \"\"\"\n",
    "    <RELLENA>\n",
    "\n",
    "parsedTrainFeat = rawTrainData.map(parsePoint)\n",
    "\n",
    "numCategories = (parsedTrainFeat\n",
    "                 .flatMap(lambda x: x)\n",
    "                 .distinct()\n",
    "                 .map(lambda x: (x[0], 1))\n",
    "                 .reduceByKey(lambda x, y: x + y)\n",
    "                 .sortByKey()\n",
    "                 .collect())\n",
    "\n",
    "print numCategories[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Extraer características (3b)\n",
    "Test.assertEquals(numCategories[2][1], 135, 'implementación incorrecta de parsePoint')\n",
    "Test.assertEquals(numCategories[32][1], 4, 'implementación incorrecta de parsePoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3c) crear un diccionario OHE para el dataset **\n",
    "#### parsePoint devuelve un data point como una lista de tuplas `(featureID, category)`  que tienen el mismo formato que el dataset estudiado en las partes 1 y 2. Crea un diccionario OHE que use la función implementada en la parte (2c). Asumimos por simplicidad que todas las características en el dataset son categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: Reemplaza <RELLENA> con el código apropiado\n",
    "ctrOHEDict = <RELLENA>\n",
    "numCtrOHEFeats = len(ctrOHEDict.keys())\n",
    "print numCtrOHEFeats\n",
    "print ctrOHEDict[(0, '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST crear un diccionario OHE para el dataset (3c)\n",
    "Test.assertEquals(numCtrOHEFeats, 13752, 'numero incorrecto de características en ctrOHEDict')\n",
    "Test.assertTrue((0, '') in ctrOHEDict, 'características incorrectas en ctrOHEDict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (3d) Aplicar OHE al dataset **\n",
    "#### Usemos ahora el diccionario OHE empezando con los datos en bruto del training creando un RDD de objetos [LabeledPoint](http://spark.apache.org/docs/1.3.1/api/python/pyspark.mllib.html#pyspark.mllib.regression.LabeledPoint) que usen las características OHE. Para hacer esto completa la implementación de la función `parseOHEPoint` . Sugerencia: `parseOHEPoint` es una extensión de la función `parsePoint`  de la parte (3b) y usa la función `oneHotEncoding` de la parte (1d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: Reemplaza <RELLENA> con el código apropiado\n",
    "def parseOHEPoint(point, OHEDict, numOHEFeats):\n",
    "    \"\"\" Obtener la etiqueta y el vector de características de una observación en bruto\n",
    "\n",
    "    Note:\n",
    "        Usa la función  `oneHotEncoding` en esta implementacion.\n",
    "\n",
    "    Args:\n",
    "        point (str): Una cadena separada por comas donde el primer valor es la etiqueta y el resto son \n",
    "            características.\n",
    "        OHEDict (dict of (int, str) to int): mapedo de (featureID, value) a un entero único.\n",
    "        numOHEFeats (int): el número de características únicas en el dataset de training.\n",
    "    Returns:\n",
    "        LabeledPoint: Contiene la etiqueta de la observación y el one-hot-encoding de las características en bruto basado\n",
    "        del diccionario OHE proporcionado.\n",
    "    \"\"\"\n",
    "    <RELLENA>\n",
    "\n",
    "OHETrainData = rawTrainData.map(lambda point: parseOHEPoint(point, ctrOHEDict, numCtrOHEFeats))\n",
    "OHETrainData.cache()\n",
    "print OHETrainData.take(1)\n",
    "\n",
    "# checquea que la funcioin oneHotEncoding se usa en parseOHEPoint\n",
    "backupOneHot = oneHotEncoding\n",
    "oneHotEncoding = None\n",
    "withOneHot = False\n",
    "try: parseOHEPoint(rawTrainData.take(1)[0], ctrOHEDict, numCtrOHEFeats)\n",
    "except TypeError: withOneHot = True\n",
    "oneHotEncoding = backupOneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Aplicar OHE al dataset (3d)\n",
    "numNZ = sum(parsedTrainFeat.map(lambda x: len(x)).take(5))\n",
    "numNZAlt = sum(OHETrainData.map(lambda lp: len(lp.features.indices)).take(5))\n",
    "Test.assertEquals(numNZ, numNZAlt, 'implementación incorrecta en parseOHEPoint')\n",
    "Test.assertTrue(withOneHot, 'oneHotEncoding no presente en parseOHEPoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Visualización 1: Frecuencia de características **\n",
    "#### visualizaremos ahora el número de veces que aparecen las características OHE en el dataset de training. Primero se calculará el numero que aparece cada característica, después el 'bucket' de características para esas cuentas. los 'buckets' tienen un tamaño de potencia de 2 de modo que el primer 'bucket' se corresponde con características que aparecen exactamente 1 vez ( $ \\scriptsize 2^0 $ ), el segundo con características que aparecen dos veces ( $ \\scriptsize 2^1 $ ) el tercero con características que aparecen entre 3 y 4 ( $ \\scriptsize 2^2 $ ) veces, el quinto de 5 a 8  ( $ \\scriptsize 2^3 $ ) etc.. el gráfico muestra el logaritmo de los límites de los 'buckets' vs el logaritmo del número de características que tienen el contador que cae dentro de los 'buckets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bucketFeatByCount(featCount):\n",
    "    \"\"\"Bucket the counts by powers of two.\"\"\"\n",
    "    for i in range(11):\n",
    "        size = 2 ** i\n",
    "        if featCount <= size:\n",
    "            return size\n",
    "    return -1\n",
    "\n",
    "featCounts = (OHETrainData\n",
    "              .flatMap(lambda lp: lp.features.indices)\n",
    "              .map(lambda x: (x, 1))\n",
    "              .reduceByKey(lambda x, y: x + y))\n",
    "featCountsBuckets = (featCounts\n",
    "                     .map(lambda x: (bucketFeatByCount(x[1]), 1))\n",
    "                     .filter(lambda (k, v): k != -1)\n",
    "                     .reduceByKey(lambda x, y: x + y)\n",
    "                     .collect())\n",
    "print featCountsBuckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x, y = zip(*featCountsBuckets)\n",
    "x, y = np.log(x), np.log(y)\n",
    "\n",
    "def preparePlot(xticks, yticks, figsize=(10.5, 6), hideLabels=False, gridColor='#999999',\n",
    "                gridWidth=1.0):\n",
    "    \"\"\"Template for generating the plot layout.\"\"\"\n",
    "    plt.close()\n",
    "    fig, ax = plt.subplots(figsize=figsize, facecolor='white', edgecolor='white')\n",
    "    ax.axes.tick_params(labelcolor='#999999', labelsize='10')\n",
    "    for axis, ticks in [(ax.get_xaxis(), xticks), (ax.get_yaxis(), yticks)]:\n",
    "        axis.set_ticks_position('none')\n",
    "        axis.set_ticks(ticks)\n",
    "        axis.label.set_color('#999999')\n",
    "        if hideLabels: axis.set_ticklabels([])\n",
    "    plt.grid(color=gridColor, linewidth=gridWidth, linestyle='-')\n",
    "    map(lambda position: ax.spines[position].set_visible(False), ['bottom', 'top', 'left', 'right'])\n",
    "    return fig, ax\n",
    "\n",
    "# generate layout and plot data\n",
    "fig, ax = preparePlot(np.arange(0, 10, 1), np.arange(4, 14, 2))\n",
    "ax.set_xlabel(r'$\\log_e(bucketSize)$'), ax.set_ylabel(r'$\\log_e(countInBucket)$')\n",
    "plt.scatter(x, y, s=14**2, c='#d6ebf2', edgecolors='#8cbfd0', alpha=0.75)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3e) características no vistas **\n",
    "#### Naturalmente queremos repetir el proceso de la parte (3d) para computar características OHE para los dataset de validación y de test. Sin embargo debemos de ser cuidadosos, como alguno de los valores categóricos aparecerán probablemente en los nuevos datos que no existen en el dataset de training. Para resolverlo actualiza la función  `oneHotEncoding()` de la parte (1d) para ignorar la categorias no vistas previamentes y entonces computar las características OHE para los datos de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: Reemplaza <RELLENA> con el código apropiado\n",
    "def oneHotEncoding(rawFeats, OHEDict, numOHEFeats):\n",
    "    \"\"\"produce un one-hot-encoding de una lista de características y un diccionario OHE\n",
    "\n",
    "    Note:\n",
    "        Si una tupla (featureID, value) no tiene una clave correspondiente en OHEDict se ignorará\n",
    "\n",
    "    Args:\n",
    "        rawFeats (list of (int, str)): Las características correspondientes a una única observacion. cada\n",
    "            caracteristica consiste en una tupla de featureID y el valor de la características (ej. sampleOne)\n",
    "            \n",
    "        OHEDict (dict): Un mapeo de (featureID, value) a un entero único.\n",
    "        \n",
    "        numOHEFeats (int): El número total de características OHE únicas (combinación de featureID y valor)\n",
    "\n",
    "    Returns:\n",
    "        SparseVector: Un SparseVector de longitud numOHEFeats con índices iguales a los identificadores unicos por las\n",
    "        combinaciones (featureID, Value) que ocurren en la observacion y con valores iguales a 1.0\n",
    "    \"\"\"\n",
    "    <RELLENA>\n",
    "\n",
    "OHEValidationData = rawValidationData.map(lambda point: parseOHEPoint(point, ctrOHEDict, numCtrOHEFeats))\n",
    "OHEValidationData.cache()\n",
    "print OHEValidationData.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST  características no vistas (3e)\n",
    "numNZVal = (OHEValidationData\n",
    "            .map(lambda lp: len(lp.features.indices))\n",
    "            .sum())\n",
    "Test.assertEquals(numNZVal, 6831, 'número incorrecto de características')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte 4: predicción CTR y evaluación logloss **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (4a) regresión logística **\n",
    "#### Ahora estamos preparados para entrenar nuestro primer clasificador CTR. un clasificador natural es la regresión logística ya que modela la probabilidad de un evento de click en una respuesta binaria y cuando se trabaja con eventos raros la predición probabilistica es útil. Usaremos [LogisticRegressionWithSGD](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.classification.LogisticRegressionWithSGD) para entrenar un modelo usando `OHETrainData` con la configuración de hiperparámetros dada.   `LogisticRegressionWithSGD` devuelve un [LogisticRegressionModel](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LogisticRegressionModel).  A continuación usa los atributos `LogisticRegressionModel.weights` y `LogisticRegressionModel.intercept` para imprimir los parámetros del modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "\n",
    "# hiperparametros\n",
    "numIters = 50\n",
    "stepSize = 10.\n",
    "regParam = 1e-6\n",
    "regType = 'l2'\n",
    "includeIntercept = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: Reemplaza <RELLENA> con el código apropiado\n",
    "model0 = <RELLENA>\n",
    "sortedWeights = sorted(model0.weights)\n",
    "print sortedWeights[:5], model0.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST regresión logística (4a)\n",
    "Test.assertTrue(np.allclose(model0.intercept, 0.517827546956), 'valor incorrecto para model0.intercept')\n",
    "Test.assertTrue(np.allclose(sortedWeights[0:5],\n",
    "               [-0.53926951604577589, -0.50125820376553387, -0.48510539113089984, -0.44891726344197702, -0.44756735338568415]),\n",
    "                'valor incorrecto para model0.weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (4b) Pérdida logaritmica - Log loss **\n",
    "#### Utilizaremos log loss para evaluar la calidad de los modelos. Log loss se define como:  $$  \\begin{align} \\scriptsize \\ell_{log}(p, y) = \\begin{cases} -\\log (p) & \\text{if } y = 1 \\\\\\ -\\log(1-p) & \\text{if } y = 0 \\end{cases} \\end{align} $$ donde $ \\scriptsize p$ es una probabilidad entre 0 y 1 y $ \\scriptsize y$ es una etiqueta que puede ser 0 ó 1. Log loss es el criterio de evaluación estándar cuando se predicen eventos raros como la tasa de clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: Reemplaza <RELLENA> con el código apropiado\n",
    "from math import log\n",
    "\n",
    "def computeLogLoss(p, y):\n",
    "    \"\"\" calcula el valor de log loss para una probabilidad dada y una etiqueta\n",
    "\n",
    "    Note:\n",
    "        log(0) no esta definido de modo que cuando p es 0 necesitamos añadir un pequeño valor (epsilon)\n",
    "        y cuando p es 1 necesitamos restar un pequeño valor (epsilon)\n",
    "\n",
    "    Args:\n",
    "        p (float): Una probabilidad entre 0 y 1 \n",
    "        y (int): Una etiqueta 0 ó 1\n",
    "\n",
    "    Returns:\n",
    "        float: el valor de log loss\n",
    "    \"\"\"\n",
    "    epsilon = 10e-12\n",
    "    <RELLENA>\n",
    "\n",
    "print computeLogLoss(.5, 1)\n",
    "print computeLogLoss(.5, 0)\n",
    "print computeLogLoss(.99, 1)\n",
    "print computeLogLoss(.99, 0)\n",
    "print computeLogLoss(.01, 1)\n",
    "print computeLogLoss(.01, 0)\n",
    "print computeLogLoss(0, 1)\n",
    "print computeLogLoss(1, 1)\n",
    "print computeLogLoss(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Log loss (4b)\n",
    "Test.assertTrue(np.allclose([computeLogLoss(.5, 1), computeLogLoss(.01, 0), computeLogLoss(.01, 1)],\n",
    "                            [0.69314718056, 0.0100503358535, 4.60517018599]),\n",
    "                'computeLogLoss no es correcto')\n",
    "Test.assertTrue(np.allclose([computeLogLoss(0, 1), computeLogLoss(1, 1), computeLogLoss(1, 0)],\n",
    "                            [25.3284360229, 1.00000008275e-11, 25.3284360229]),\n",
    "                'computeLogLoss se necesita alejar p de 0 y 1 usando epsilon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (4c)  Baseline log loss **\n",
    "#### Usaremos la función de la parte (4b) para computar la baseline de log en los datos de training. un modelo baseline simple será aquel que haga siempre la misma predicción independientemente del datapoint, devolviendo para cualquier punto la fracción de los puntos de entreamiento que corresponden a eventos de click (donde la etiqueta es 1). esto es la media de las etiquetas de training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: Reemplaza <RELLENA> con el código apropiado\n",
    "# nota: el datase tiene la tasa de click muy alta por diseño \n",
    "# en la practica los clicks pueden ser de uno dos ordenes de magnitud inferior\n",
    "classOneFracTrain = <RELLENA>\n",
    "print classOneFracTrain\n",
    "\n",
    "logLossTrBase = <RELLENA>\n",
    "print 'Baseline Train Logloss = {0:.3f}\\n'.format(logLossTrBase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Baseline log loss (4c)\n",
    "Test.assertTrue(np.allclose(classOneFracTrain,0.204887218045), 'valor incorrecto para classOneFracTrain')\n",
    "Test.assertTrue(np.allclose(logLossTrBase, 0.507103356072), 'valor incorrecto para logLossTrBase')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (4d) Probabilidad predicha **\n",
    "#### Para computar la log loss para el modelo entrenado en la parte (4a) necesitamos escribir el código para generar predicciones para este modelo. Escribe una función que calcule la predicción lineal para este modelo de regresión logística y la pase por una función sigmoide [sigmoid function](http://en.wikipedia.org/wiki/Sigmoid_function) $ \\scriptsize \\sigma(t) = (1+ e^{-t})^{-1} $ y que devuelva la predicción probabilística del modelo, calcula entonces las prediciones probabilísticas en sobre el dataset de training.\n",
    "\n",
    "#### Nota que cuando incorporamos un interceptor en nuestras predicciones simplemente añadimos este interceptor al valor de las predicciones obtenidad de los pesos y características. De manera alternativa, si el interceptor lo incluimos como el primer peso necesitaríamos añadir una característica correspondiente a nuestros datos que tuviera siempre el valor 1. (no es el caso aqui)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: Reemplaza <RELLENA> con el código apropiado\n",
    "from math import exp #  exp(-t) = e^-t\n",
    "\n",
    "def getP(x, w, intercept):\n",
    "    \"\"\" Calcula la probabilidad para una observación dada un conjunto de pesos e interceptor.\n",
    "\n",
    "    Note:\n",
    "        Limitaremos nuestras prediciones en bruto entre 20 y -20 por propósitos numéricos\n",
    "\n",
    "    Args:\n",
    "        x (SparseVector): Un vector con valores de 1.0 para las características que existan en esta observación 0.0 en otro caso\n",
    "       \n",
    "        w (DenseVector): Un vector de pesos (betas) para el modelo.\n",
    "        intercept (float): El interceptor del modelo.\n",
    "\n",
    "    Returns:\n",
    "        float: Una probabilidad entre 0 y 1.\n",
    "    \"\"\"\n",
    "    rawPrediction = <RELLENA>\n",
    "\n",
    "    # limitar la predicción\n",
    "    rawPrediction = min(rawPrediction, 20)\n",
    "    rawPrediction = max(rawPrediction, -20)\n",
    "    return <RELLENA>\n",
    "\n",
    "trainingPredictions = <RELLENA>\n",
    "\n",
    "print trainingPredictions.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Probabilidad predicha (4d)\n",
    "Test.assertTrue(np.allclose(trainingPredictions.sum(), 328.867397104),\n",
    "                'valor incorrecto para trainingPredictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (4e) Evaluar el modelo **\n",
    "#### Ahora estmos listo para evaluar la calidad del modelo que entrenamos en la parte (4a). Para hacer esto primero escribimos una función general que tome un modelo y datos como entrada y devuelva log loss. Utiliza esta función en los datos de training OHE y compara el resultado con el log loss baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: Reemplaza <RELLENA> con el código apropiado\n",
    "def evaluateResults(model, data):\n",
    "    \"\"\" Calcula log loss para los datos dado el modelo\n",
    "\n",
    "    Args:\n",
    "        model (LogisticRegressionModel): Un modelo de regresión logística.\n",
    "        data (RDD of LabeledPoint): Etiquetas y características para cada observación.\n",
    "\n",
    "    Returns:\n",
    "        float: Log loss de los datos.\n",
    "    \"\"\"\n",
    "    <RELLENA>\n",
    "\n",
    "logLossTrLR0 = evaluateResults(model0, OHETrainData)\n",
    "print ('logloss para para las características de train OHE:\\n\\tBaseline = {0:.3f}\\n\\tLogReg = {1:.3f}'\n",
    "       .format(logLossTrBase, logLossTrLR0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST evaluar el modelo (4e)\n",
    "Test.assertTrue(np.allclose(logLossTrLR0, 0.272726463634), 'valor incorrecto para logLossTrLR0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (4f) Validación log loss **\n",
    "#### A continuación usaremos la misma lógica que en las partes (4c) y (4e) para computar log loss en los datos de validación tanto para el modelo baseline como para  el modelo de regresión logística. Nota: El modelo baseline de validación debería serguir basado en la fracción de etiquetas del dataset de training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: Reemplaza <RELLENA> con el código apropiado\n",
    "logLossValBase = <RELLENA>\n",
    "\n",
    "logLossValLR0 = <RELLENA>\n",
    "print ('logloss para las características de validación OHE:\\n\\tBaseline = {0:.3f}\\n\\tLogReg = {1:.3f}'\n",
    "       .format(logLossValBase, logLossValLR0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Validación log los (4f)\n",
    "Test.assertTrue(np.allclose(logLossValBase,0.487561652546), 'valor incorrecto para logLossValBase')\n",
    "Test.assertTrue(np.allclose(logLossValLR0,0.444984067678), 'valor incorrecto para logLossValLR0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Visualización 2: curva ROC**\n",
    "#### Visualizaremos ahora como de bien el modelo predice nuestro objetivo. Vamos a genera un gráfico de la curva ROC que muestra la relación entre la tasa de falsos positivos y verdaderos positivos al liberar el límite requerido para predecir una entrada positiva. El modelo aleatorio se representa con una linea discontinua."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelsAndScores = OHEValidationData.map(lambda lp:\n",
    "                                            (lp.label, getP(lp.features, model0.weights, model0.intercept)))\n",
    "labelsAndWeights = labelsAndScores.collect()\n",
    "labelsAndWeights.sort(key=lambda (k, v): v, reverse=True)\n",
    "labelsByWeight = np.array([k for (k, v) in labelsAndWeights])\n",
    "\n",
    "length = labelsByWeight.size\n",
    "truePositives = labelsByWeight.cumsum()\n",
    "numPositive = truePositives[-1]\n",
    "falsePositives = np.arange(1.0, length + 1, 1.) - truePositives\n",
    "\n",
    "truePositiveRate = truePositives / numPositive\n",
    "falsePositiveRate = falsePositives / (length - numPositive)\n",
    "\n",
    "# Generate layout and plot data\n",
    "fig, ax = preparePlot(np.arange(0., 1.1, 0.1), np.arange(0., 1.1, 0.1))\n",
    "ax.set_xlim(-.05, 1.05), ax.set_ylim(-.05, 1.05)\n",
    "ax.set_ylabel('True Positive Rate (Sensitivity)')\n",
    "ax.set_xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.plot(falsePositiveRate, truePositiveRate, color='#8cbfd0', linestyle='-', linewidth=3.)\n",
    "plt.plot((0., 1.), (0., 1.), linestyle='--', color='#d6ebf2', linewidth=2.)  # Baseline model\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
